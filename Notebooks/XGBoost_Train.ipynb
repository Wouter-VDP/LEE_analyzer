{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from helpfunction import sciNot\n",
    "\n",
    "%matplotlib inline\n",
    "gr      = 1.618"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-14-63d6ca0d90b2>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-63d6ca0d90b2>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    output_dir = \"../output/Track_Shower_tune3/\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "min_dedx_hits=3\n",
    "min_reco_e=0.03\n",
    "z_dead_start = 675\n",
    "z_dead_end=z_dead_start+100\n",
    "\n",
    "mu_cutoff=5 #0.5\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "input_dir = \"../Input/pandora_pdg_cut/\"\n",
    "output_dir = \"../output/Track_Shower_tune3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insertscore(df,model,columns_train,name):\n",
    "    df[name]    = model.predict_proba(df[columns_train].as_matrix())[:,1]\n",
    "    return df\n",
    "\n",
    "def insertscores(df,columns,columns_mu,tr_or_sh):\n",
    "    files = glob.glob(input_dir+\"XGBoost/*.pkl\")\n",
    "    names = [file.split(\"/\")[-1].split(\".\")[0][6:] for file in files]\n",
    "    models = [joblib.load(file) for file in files]\n",
    "    for name,model in zip(names,models):\n",
    "        if tr_or_sh in name:\n",
    "            if \"mu\" in name:\n",
    "                df = insertscore(df,model,columns_mu,name)\n",
    "            else:\n",
    "                df = insertscore(df,model,columns,name)\n",
    "    return df\n",
    "\n",
    "\n",
    "#The statistical uncertainity per bin of the binned data.\n",
    "#If there are weights then the uncertainity will be the root of the\n",
    "#sum of the weights squared.\n",
    "def hist_bin_uncertainty(data, weights, bin_edges):\n",
    "    # Bound the data and weights to be within the bin edges\n",
    "    in_range_index = [idx for idx in range(len(data)) if data[idx] > min(bin_edges) and data[idx] < max(bin_edges)]\n",
    "    in_range_data = np.asarray([data[idx] for idx in in_range_index])\n",
    "    in_range_weights = np.asarray([weights[idx] for idx in in_range_index])\n",
    "\n",
    "    # Bin the weights with the same binning as the data\n",
    "    bin_index = np.digitize(in_range_data, bin_edges)\n",
    "    # N.B.: range(1, bin_edges.size) is used instead of set(bin_index) as if\n",
    "    # there is a gap in the data such that a bin is skipped no index would appear\n",
    "    # for it in the set\n",
    "    binned_weights = np.asarray(\n",
    "        [in_range_weights[np.where(bin_index == idx)[0]] for idx in range(1, len(bin_edges))])\n",
    "    bin_uncertainties = np.asarray(\n",
    "        [np.sqrt(np.sum(np.square(w))) for w in binned_weights])\n",
    "    return bin_uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tune1\n",
    "\n",
    "input_tr = [input_dir+\"lee_75k/lee_75k_track_9.pckl\",\n",
    "            input_dir+\"intime/intime_track_7.pckl\",\n",
    "            \n",
    "            input_dir+\"nue_tune3/nue_tune3_track_0.pckl\",\n",
    "            #input_dir+\"nue_tune3/nue_tune3_track_1.pckl\",\n",
    "            #input_dir+\"nue_tune3/nue_tune3_track_2.pckl\",\n",
    "            #input_dir+\"nue_tune3/nue_tune3_track_3.pckl\",\n",
    "            #input_dir+\"nue_tune3/nue_tune3_track_4.pckl\",\n",
    "            \n",
    "            #input_dir+\"nu_tune3/nu_tune3_track_4.pckl\",\n",
    "            #input_dir+\"nu_tune3/nu_tune3_track_5.pckl\",\n",
    "            input_dir+\"nu_tune3/nu_tune3_track_0.pckl\",\n",
    "            input_dir+\"nu_tune3/nu_tune3_track_1.pckl\",\n",
    "           ]\n",
    "\n",
    "input_test = [#input_dir+\"nu_tune3/nu_tune3_track_0.pckl\",\n",
    "              #input_dir+\"nu_tune3/nu_tune3_track_1.pckl\",\n",
    "              input_dir+\"nu_tune3/nu_tune3_track_2.pckl\",\n",
    "              input_dir+\"nu_tune3/nu_tune3_track_3.pckl\",\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_tr_data = [input_dir+\"XGBoost/bnb/trackFrame_data_bnb.pckl\",\n",
    "#                 input_dir+\"XGBoost/bnbext/trackFrame_data_bnbext.pckl\"\n",
    "#                ]\n",
    "\n",
    "intput_tr_df = [ pd.read_pickle(x) for x in input_tr]\n",
    "df_tr_train = pd.concat(intput_tr_df,ignore_index=True,copy=False) \n",
    "\n",
    "intput_tr_df = [ pd.read_pickle(x) for x in input_test]\n",
    "df_tr_test = pd.concat(intput_tr_df,ignore_index=True,copy=False) \n",
    "\n",
    "\n",
    "# Do some things before training on the frame\n",
    "df_tr_train = pd.get_dummies(df_tr_train,columns=[\"track_is_daughter\",\"track_daughter\"],drop_first=True)\n",
    "df_tr_train[\"true_mu\"] = df_tr_train[\"matched_tracks\"].abs() == 13\n",
    "df_tr_train[\"true_e\"] = df_tr_train[\"matched_tracks\"] == 11\n",
    "\n",
    "\n",
    "# Do some things before testing on the frame\n",
    "print(\"train\",df_tr_train.columns)\n",
    "print(\"test\",df_tr_test.columns)\n",
    "df_tr_test = pd.get_dummies(df_tr_test,columns=[\"track_is_daughter\",\"track_daughter\"],drop_first=True)\n",
    "\n",
    "df_tr_test[\"true_mu\"] = df_tr_test[\"matched_tracks\"].abs() == 13\n",
    "df_tr_test[\"true_e\"] = df_tr_test[\"matched_tracks\"] == 11\n",
    "\n",
    "\n",
    "columns_track_XGB =       [\"track_vtxdistance\", \"track_maxangle\",\n",
    "                           \"track_spacepoint_dqdx_ratio\", \"predict_cos\", \"track_pca\",\n",
    "                           \"track_dedx_best_w\",\n",
    "                           \"predict_mu\", \"predict_pi\",\n",
    "                           \"track_dedx_hits_w\", \"predict_p\",\n",
    "                           \"track_dedx_w\",\n",
    "                           \"track_hitsratio_w\", \"predict_em\", \n",
    "                           \"track_len\"\n",
    "                          ]\n",
    "\n",
    "columns_track_XGB_mu = columns_track_XGB+[\"track_hits_w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tr_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For now, quick fix: require at least x hits in track_dedx_hits, otherwise track_dedx is nonsence.\n",
    "# Also require a reconstructed energy of at leact x Mev\n",
    "df_tr_train = df_tr_train[df_tr_train[\"track_dedx_hits_w\"]>=min_dedx_hits]\n",
    "df_tr_test = df_tr_test[df_tr_test[\"track_dedx_hits_w\"]>=min_dedx_hits]\n",
    "df_tr_train = df_tr_train[df_tr_train[\"track_energy_w\"]>=min_reco_e]\n",
    "df_tr_test = df_tr_test[df_tr_test[\"track_energy_w\"]>=min_reco_e]\n",
    "df_tr_train = df_tr_train[~df_tr_train[\"track_start_z\"].between(z_dead_start,z_dead_end)]\n",
    "df_tr_test = df_tr_test[~df_tr_test[\"track_start_z\"].between(z_dead_start,z_dead_end)]\n",
    "\n",
    "df_tr_train.head()\n",
    "print(df_tr_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_tr_train[columns_track_XGB].as_matrix()\n",
    "X_test  = df_tr_test[columns_track_XGB].as_matrix()\n",
    "\n",
    "X_train_mu = df_tr_train[columns_track_XGB_mu].as_matrix()\n",
    "X_test_mu  = df_tr_test[columns_track_XGB_mu].as_matrix()\n",
    "\n",
    "Y_train = df_tr_train[[\"true_mu\",\"true_e\",\"track_cle\"]]\n",
    "Y_test = df_tr_test[[\"true_mu\",\"true_e\",\"track_cle\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "label = \"true_mu\"\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train_mu, Y_train[label])\n",
    "print(classification_report(Y_test[label], model.predict(X_test_mu)))\n",
    "joblib.dump(model, input_dir+\"XGBoost/model_tr_mu.pkl\") \n",
    "y_pred_mu = model.predict_proba(X_test_mu)\n",
    "y_pred_mu_train = model.predict_proba(X_train_mu)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(len(columns_track_XGB_mu)):\n",
    "    print(\"%d. feature %s(%f)\" % (f + 1, columns_track_XGB_mu[indices[f]],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "label = \"true_e\"\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train[y_pred_mu_train[:,1]<mu_cutoff], Y_train[label][y_pred_mu_train[:,1]<mu_cutoff])\n",
    "print(classification_report(Y_test[label], model.predict(X_test)))\n",
    "joblib.dump(model, input_dir+\"XGBoost/model_tr_e.pkl\") \n",
    "y_pred_e = model.predict_proba(X_test)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(len(columns_track_XGB)):\n",
    "    print(\"%d. feature %s(%f)\" % (f + 1, columns_track_XGB[indices[f]],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "label = \"track_cle\"\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train[y_pred_mu_train[:,1]<mu_cutoff], Y_train[label][y_pred_mu_train[:,1]<mu_cutoff])\n",
    "print(classification_report(Y_test[label], model.predict(X_test)))\n",
    "joblib.dump(model, input_dir+\"XGBoost/model_tr_cle.pkl\") \n",
    "y_pred_cle = model.predict_proba(X_test)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(len(columns_track_XGB)):\n",
    "    print(\"%d. feature %s(%f)\" % (f + 1, columns_track_XGB[indices[f]],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# XGB classification\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "fig,ax=plt.subplots(ncols=3,nrows=2,figsize=(7*gr,6),sharex=True)\n",
    "plt.suptitle(r\"XGBoost muon/electron track classifier (test dataset)\")\n",
    "N=50\n",
    "muon_cut = 0.05\n",
    "electron_cut=0.7\n",
    "close_e_cut=0.7\n",
    "\n",
    "\n",
    "# Electron track classification\n",
    "y_test_e = Y_test[\"true_e\"]\n",
    "arr_e  = y_pred_e[y_test_e==1][:,1]\n",
    "arr_ne = y_pred_e[y_test_e==0][:,1]\n",
    "\n",
    "# Electron track classification\n",
    "y_test_cle = Y_test[\"track_cle\"]\n",
    "arr_cl_e  = y_pred_e[y_test_cle==1][:,1]\n",
    "arr_cl_ne = y_pred_e[y_test_cle==0][:,1]\n",
    "\n",
    "# Muon track classification\n",
    "y_test_mu = Y_test[\"true_mu\"]\n",
    "arr_mu  = y_pred_mu[y_test_mu==1][:,1]\n",
    "arr_nmu = y_pred_mu[y_test_mu==0][:,1]\n",
    "\n",
    "label_mu=(r\"$\\mu^+/ \\:\\mu^-$ matched (\"+str(len(arr_mu))+\")\",\"Other (\"+str(len(arr_nmu))+\")\")\n",
    "label_e=(r\"$e^-$ matched (\"+str(len(arr_e))+\")\",\"Other (\"+str(len(arr_ne))+\")\")\n",
    "label_cl_e=(r\"$e^-$ closest (\"+str(len(arr_cl_e))+\")\",\"Other (\"+str(len(arr_cl_ne))+\")\")\n",
    "\n",
    "ax[0][0].axvspan(muon_cut,1, alpha=0.15, color=\"red\",label=\"Rejected objects > \"+str(muon_cut) )\n",
    "ax[0][0].hist([arr_mu,arr_nmu],histtype=\"step\", bins=N, fill=False,label=label_mu,density=True)\n",
    "ax[0][0].set_ylabel(\"Normalised\")\n",
    "\n",
    "\n",
    "ax[1][0].axvspan(muon_cut,1, alpha=0.15, color=\"red\",label=\"Rejected objects > \"+str(muon_cut) )\n",
    "ax[1][0].hist([arr_mu,arr_nmu],histtype=\"step\", bins=N, fill=False,label=label_mu,density=True)\n",
    "ax[1][0].set_ylim(0,5)\n",
    "ax[1][0].set_ylabel(\"Normalised\")\n",
    "ax[1][0].set_xlabel(\"PID Probability\")\n",
    "\n",
    "ax[0][1].axvspan(electron_cut,1, alpha=0.15, color=\"green\",label=\"Accepted objects > \"+str(electron_cut) )\n",
    "ax[0][1].hist([arr_e,arr_ne],histtype=\"step\", bins=N, fill=False,label=label_e,density=True)\n",
    "\n",
    "ax[1][1].axvspan(electron_cut,1, alpha=0.15, color=\"green\",label=\"Accepted objects > \"+str(electron_cut) )\n",
    "ax[1][1].hist([arr_e,arr_ne],histtype=\"step\", bins=N, fill=False,label=label_e,density=True)\n",
    "ax[1][1].set_ylim(0,3)\n",
    "ax[1][1].set_xlabel(\"Probability\")\n",
    "\n",
    "\n",
    "ax[0][2].axvspan(close_e_cut,1, alpha=0.15, color=\"green\",label=\"Accepted objects > \"+str(close_e_cut) )\n",
    "ax[0][2].hist([arr_cl_e,arr_cl_ne],histtype=\"step\", bins=N, fill=False,label=label_cl_e,density=True)\n",
    "\n",
    "ax[1][2].axvspan(close_e_cut,1, alpha=0.15, color=\"green\",label=\"Accepted objects > \"+str(close_e_cut) )\n",
    "ax[1][2].hist([arr_cl_e,arr_cl_ne],histtype=\"step\", bins=N, fill=False,label=label_cl_e,density=True)\n",
    "ax[1][2].set_ylim(0,3)\n",
    "ax[1][2].set_xlabel(\"Probability\")\n",
    "\n",
    "#offset=0.05\n",
    "handles, labels = ax[0][0].get_legend_handles_labels()\n",
    "ax[0][0].legend(handles[::-1], labels[::-1],loc=\"upper center\")\n",
    "handles, labels = ax[0][1].get_legend_handles_labels()\n",
    "ax[0][1].legend(handles[::-1], labels[::-1],loc=\"upper center\")\n",
    "handles, labels = ax[0][2].get_legend_handles_labels()\n",
    "ax[0][2].legend(handles[::-1], labels[::-1],loc=\"upper center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(top=0.92)\n",
    "plt.savefig(output_dir+\"XGB_track.pdf\")\n",
    "\n",
    "print(\"Cut value:\",muon_cut,\"removes\", sciNot(sum(arr_mu>muon_cut) / len(arr_mu)*100),\"% of muon tagged tracks and\",\n",
    "      sciNot(sum(arr_nmu>muon_cut) / len(arr_nmu)*100),\"% of not-muon tagged tracks.\")\n",
    "\n",
    "print(\"Cut value:\",electron_cut,\"keeps\", sciNot(sum(arr_e>electron_cut) / len(arr_e)*100),\"% of electron tagged tracks and\",\n",
    "      sciNot(sum(arr_ne>electron_cut) / len(arr_ne)*100),\"% of not-electron tagged tracks.\")\n",
    "\n",
    "print(\"Cut value:\",close_e_cut,\"keeps\", sciNot(sum(arr_cl_e>close_e_cut) / len(arr_cl_e)*100),\"% of closest electron tagged tracks and\",\n",
    "      sciNot(sum(arr_cl_ne>close_e_cut) / len(arr_ne)*100),\"% of not-closest-electron tagged tracks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sh = [input_dir+\"intime/intime_shower_7.pckl\",\n",
    "            \n",
    "            input_dir+\"nue_tune3/nue_tune3_shower_0.pckl\",\n",
    "            #input_dir+\"nue_tune3/nue_tune3_shower_1.pckl\",\n",
    "            #input_dir+\"nue_tune3/nue_tune3_shower_2.pckl\",\n",
    "            #input_dir+\"nue_tune3/nue_tune3_shower_3.pckl\",\n",
    "            #input_dir+\"nue_tune3/nue_tune3_shower_4.pckl\",\n",
    "            \n",
    "            input_dir+\"nu_tune3/nu_tune3_shower_0.pckl\",\n",
    "            input_dir+\"nu_tune3/nu_tune3_shower_1.pckl\",\n",
    "            #input_dir+\"nu_tune3/nu_tune3_shower_6.pckl\",\n",
    "            #input_dir+\"nu_tune3/nu_tune3_shower_7.pckl\",\n",
    "           ]\n",
    "\n",
    "input_test = [#input_dir+\"nu_tune3/nu_tune3_shower_0.pckl\",\n",
    "              #input_dir+\"nu_tune3/nu_tune3_shower_1.pckl\",\n",
    "              input_dir+\"nu_tune3/nu_tune3_shower_2.pckl\",\n",
    "              input_dir+\"nu_tune3/nu_tune3_shower_3.pckl\",\n",
    "           ]\n",
    "\n",
    "\n",
    "#input_sh_data = [input_dir+\"XGBoost/bnb/showerFrame_data_bnb.pckl\",\n",
    "#                 input_dir+\"XGBoost/bnbext/showerFrame_data_bnbext.pckl\"\n",
    "#                ]\n",
    "\n",
    "intput_sh_df = [ pd.read_pickle(x) for x in input_sh]\n",
    "df_sh_train = pd.concat(intput_sh_df,ignore_index=True,copy=False) \n",
    "df_sh_train_lee = pd.read_pickle(input_dir+\"lee_75k/lee_75k_shower_9.pckl\")\n",
    "df_sh_train[\"bnbweight\"]=1\n",
    "df_sh_train_lee[\"bnbweight\"]=10\n",
    "df_sh_train= pd.concat([df_sh_train_lee,df_sh_train],ignore_index=True,copy=False) \n",
    "\n",
    "intput_sh_df = [ pd.read_pickle(x) for x in input_test]\n",
    "df_sh_test = pd.concat(intput_sh_df,ignore_index=True,copy=False) \n",
    "\n",
    "# Do some things before training on the frame\n",
    "df_sh_train = pd.get_dummies(df_sh_train,columns=[\"shower_is_daughter\",\"shower_daughter\"],drop_first=True)\n",
    "df_sh_train[\"true_mu\"] = df_sh_train[\"matched_showers\"].abs() == 13\n",
    "df_sh_train[\"true_e\"] = df_sh_train[\"matched_showers\"] == 11\n",
    "\n",
    "\n",
    "# Do some things before training on the frame\n",
    "df_sh_test = pd.get_dummies(df_sh_test,columns=[\"shower_is_daughter\",\"shower_daughter\"],drop_first=True)\n",
    "df_sh_test[\"true_mu\"] = df_sh_test[\"matched_showers\"].abs() == 13\n",
    "df_sh_test[\"true_e\"] = df_sh_test[\"matched_showers\"] == 11\n",
    "\n",
    "columns_shower_XGB  = [\"shower_open_angle\",\"shower_length\",\"n_showers\",\n",
    "                       \"shower_pca\", \"shower_maxangle\",\"shower_vtxdistance\",\n",
    "                       \"shower_fidvol_ratio\",\"shower_spacepoint_dqdx_ratio\",\n",
    "                       \"shower_dedx_hits_w\",\"shower_dedx_w\",\"shower_dedx_best_w\",\"shower_hitsratio_w\",\n",
    "                       #\"vtx_activity\",\"shower_is_daughter_2\",\n",
    "                       #\"shower_is_daughter_1\", \"shower_daughter_1\", \"shower_daughter_2\", #\"shower_daughter_3\",\n",
    "                       #\"shower_energy_w\", ,\"shower_hits_w\", \"shower_theta\",\"shower_energy_product\"\n",
    "                      ]\n",
    "\n",
    "columns_shower_XGB_mu = columns_shower_XGB+[\"shower_hits_w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sh_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For now, quick fix: require at least x hits in shower_dedx_hits, otherwise shower_dedx is nonsence.\n",
    "# Also require a reconstructed energy of at leact x Mev\n",
    "df_sh_train = df_sh_train[df_sh_train[\"shower_dedx_hits_w\"]>=min_dedx_hits]\n",
    "df_sh_test = df_sh_test[df_sh_test[\"shower_dedx_hits_w\"]>=min_dedx_hits]\n",
    "df_sh_train = df_sh_train[df_sh_train[\"shower_energy_w\"]>=min_reco_e]\n",
    "df_sh_test = df_sh_test[df_sh_test[\"shower_energy_w\"]>=min_reco_e]\n",
    "sf_sh_train = df_sh_train[~df_sh_train[\"shower_start_z\"].between(z_dead_start,z_dead_end)]\n",
    "df_sh_test = df_sh_test[~df_sh_test[\"shower_start_z\"].between(z_dead_start,z_dead_end)]\n",
    "\n",
    "df_sh_train.head()\n",
    "print(df_sh_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_sh_train[columns_shower_XGB].as_matrix()\n",
    "X_test  = df_sh_test[columns_shower_XGB].as_matrix()\n",
    "\n",
    "X_train_mu = df_sh_train[columns_shower_XGB_mu].as_matrix()\n",
    "X_test_mu  = df_sh_test[columns_shower_XGB_mu].as_matrix()\n",
    "\n",
    "\n",
    "X_train_weights = df_sh_train[\"bnbweight\"]\n",
    "\n",
    "Y_train = df_sh_train[[\"true_mu\",\"true_e\",\"shower_cle\"]]\n",
    "Y_test = df_sh_test[[\"true_mu\",\"true_e\",\"shower_cle\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "label = \"true_mu\"\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train_mu, Y_train[label])\n",
    "print(classification_report(Y_test[label],model.predict(X_test_mu)))\n",
    "joblib.dump(model, input_dir+\"XGBoost/model_sh_mu.pkl\") \n",
    "y_pred_mu = model.predict_proba(X_test_mu)\n",
    "y_pred_mu_train = model.predict_proba(X_train_mu)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(len(columns_shower_XGB_mu)):\n",
    "    print(\"%d. feature %s(%f)\" % (f + 1, columns_shower_XGB_mu[indices[f]],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "label = \"true_e\"\n",
    "model = XGBClassifier()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_pred_mu_train.size)\n",
    "print( Y_train[label].size)\n",
    "\n",
    "model.fit(X_train[y_pred_mu_train[:,1]<mu_cutoff], Y_train[label][y_pred_mu_train[:,1]<mu_cutoff])\n",
    "print(classification_report(Y_test[label],model.predict(X_test)))\n",
    "joblib.dump(model, input_dir+\"XGBoost/model_sh_e.pkl\")\n",
    "y_pred_e = model.predict_proba(X_test)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(len(columns_shower_XGB)):\n",
    "    print(\"%d. feature %s(%f)\" % (f + 1, columns_shower_XGB[indices[f]],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "label = \"shower_cle\"\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train[y_pred_mu_train[:,1]<mu_cutoff], Y_train[label][y_pred_mu_train[:,1]<mu_cutoff])\n",
    "print(classification_report(Y_test[label],model.predict(X_test)))\n",
    "joblib.dump(model, input_dir+\"XGBoost/model_sh_cle.pkl\") \n",
    "y_pred_cle = model.predict_proba(X_test)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(len(columns_shower_XGB)):\n",
    "    print(\"%d. feature %s(%f)\" % (f + 1, columns_shower_XGB[indices[f]],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XGB classification\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "fig,ax=plt.subplots(ncols=3,nrows=2,figsize=(7*gr,6),sharex=True)\n",
    "plt.suptitle(r\"XGBoost muon/electron shower classifier (test dataset)\")\n",
    "N=50\n",
    "muon_cut = 0.07\n",
    "electron_cut=0.90\n",
    "close_e_cut=0.9\n",
    "\n",
    "# Electron shower classification\n",
    "y_test_e = Y_test[\"true_e\"]\n",
    "arr_e  = y_pred_e[y_test_e==1][:,1]\n",
    "arr_ne = y_pred_e[y_test_e==0][:,1]\n",
    "\n",
    "# Electron shower classification\n",
    "y_test_cle = Y_test[\"shower_cle\"]\n",
    "arr_cl_e  = y_pred_e[y_test_cle==1][:,1]\n",
    "arr_cl_ne = y_pred_e[y_test_cle==0][:,1]\n",
    "\n",
    "# Muon shower classification\n",
    "y_test_mu = Y_test[\"true_mu\"]\n",
    "arr_mu  = y_pred_mu[y_test_mu==1][:,1]\n",
    "arr_nmu = y_pred_mu[y_test_mu==0][:,1]\n",
    "\n",
    "label_mu=(r\"$\\mu^+/\\mu^-$ matched (\"+str(len(arr_mu))+\")\",\"Other (\"+str(len(arr_nmu))+\")\")\n",
    "label_e=(r\"$e^-$ matched (\"+str(len(arr_e))+\")\",\"Other (\"+str(len(arr_ne))+\")\")\n",
    "label_cl_e=(r\"$e^-$ closest (\"+str(len(arr_cl_e))+\")\",\"Other (\"+str(len(arr_cl_ne))+\")\")\n",
    "\n",
    "\n",
    "ax[0][0].axvspan(muon_cut,1, alpha=0.15, color=\"red\",label=\"Rejected objects > \"+str(muon_cut) )\n",
    "ax[0][0].hist([arr_mu,arr_nmu],histtype=\"step\", bins=N, fill=False,label=label_mu,density=True)\n",
    "ax[0][0].set_ylabel(\"Normalised\")\n",
    "\n",
    "\n",
    "ax[1][0].axvspan(muon_cut,1, alpha=0.15, color=\"red\",label=\"Rejected objects > \"+str(muon_cut) )\n",
    "ax[1][0].hist([arr_mu,arr_nmu],histtype=\"step\", bins=N, fill=False,label=label_mu,density=True)\n",
    "ax[1][0].set_ylim(0,3)\n",
    "ax[1][0].set_ylabel(\"Normalised\")\n",
    "ax[1][0].set_xlabel(\"Probability\")\n",
    "\n",
    "ax[0][1].axvspan(electron_cut,1, alpha=0.15, color=\"green\",label=\"Accepted objects > \"+str(electron_cut) )\n",
    "ax[0][1].hist([arr_e,arr_ne],histtype=\"step\", bins=N, fill=False,label=label_e,density=True)\n",
    "\n",
    "ax[1][1].axvspan(electron_cut,1, alpha=0.15, color=\"green\",label=\"Accepted objects > \"+str(electron_cut) )\n",
    "ax[1][1].hist([arr_e,arr_ne],histtype=\"step\", bins=N, fill=False,label=label_e,density=True)\n",
    "ax[1][1].set_ylim(0,3)\n",
    "ax[1][1].set_xlabel(\"Probability\")\n",
    "\n",
    "\n",
    "ax[0][2].axvspan(close_e_cut,1, alpha=0.15, color=\"green\",label=\"Accepted objects > \"+str(close_e_cut) )\n",
    "ax[0][2].hist([arr_cl_e,arr_cl_ne],histtype=\"step\", bins=N, fill=False,label=label_cl_e,density=True)\n",
    "\n",
    "ax[1][2].axvspan(close_e_cut,1, alpha=0.15, color=\"green\",label=\"Accepted objects > \"+str(close_e_cut) )\n",
    "ax[1][2].hist([arr_cl_e,arr_cl_ne],histtype=\"step\", bins=N, fill=False,label=label_cl_e,density=True)\n",
    "ax[1][2].set_ylim(0,3)\n",
    "ax[1][2].set_xlabel(\"Probability\")\n",
    "\n",
    "#offset=0.05\n",
    "handles, labels = ax[0][0].get_legend_handles_labels()\n",
    "ax[0][0].legend(handles[::-1], labels[::-1],loc=\"upper center\")\n",
    "handles, labels = ax[0][1].get_legend_handles_labels()\n",
    "ax[0][1].legend(handles[::-1], labels[::-1],loc=\"upper center\")\n",
    "handles, labels = ax[0][2].get_legend_handles_labels()\n",
    "ax[0][2].legend(handles[::-1], labels[::-1],loc=\"upper center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(top=0.92)\n",
    "plt.savefig((output_dir+\"XGB_shower.pdf\")\n",
    "\n",
    "print(\"Cut value:\",muon_cut,\"removes\", sciNot(sum(arr_mu>muon_cut) / len(arr_mu)*100),\"% of muon tagged shower and\",\n",
    "      sciNot(sum(arr_nmu>muon_cut) / len(arr_nmu)*100),\"% of not-muon tagged showers.\")\n",
    "\n",
    "print(\"Cut value:\",electron_cut,\"keeps\", sciNot(sum(arr_e>electron_cut) / len(arr_e)*100),\"% of electron tagged shower and\",\n",
    "      sciNot(sum(arr_ne>electron_cut) / len(arr_ne)*100),\"% of not-electron tagged showers.\")\n",
    "\n",
    "print(\"Cut value:\",close_e_cut,\"keeps\", sciNot(sum(arr_cl_e>close_e_cut) / len(arr_cl_e)*100),\"% of closest electron tagged shower and\",\n",
    "      sciNot(sum(arr_cl_ne>close_e_cut) / len(arr_ne)*100),\"% of not-closest-electron tagged showers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "label = \"shower_cle\"\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train[y_pred_mu_train[:,1]<0.5], Y_train[label][y_pred_mu_train[:,1]<0.5],sample_weight=X_train_weights[y_pred_mu_train[:,1]<0.5])\n",
    "print(classification_report(Y_test[label],model.predict(X_test)))\n",
    "joblib.dump(model, input_dir+\"XGBoost/model_sh_cle_lee.pkl\") \n",
    "y_pred_cle_lee = model.predict_proba(X_test)\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(len(columns_shower_XGB)):\n",
    "    print(\"%d. feature %s(%f)\" % (f + 1, columns_shower_XGB[indices[f]],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Track/Shower Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_test = [input_dir+\"nue_tune3/nue_tune3_shower_1.pckl\",\n",
    "              input_dir+\"nue_tune3/nue_tune3_shower_2.pckl\",\n",
    "              #input_dir+\"nue_tune3/nue_tune3_shower_7.pckl\",\n",
    "              #input_dir+\"nue_tune3/nue_tune3_shower_8.pckl\",\n",
    "              #input_dir+\"nue_tune3/nue_tune3_shower_9.pckl\"\n",
    "              ]\n",
    "\n",
    "intput_sh_df = [ pd.read_pickle(x) for x in input_test]\n",
    "df_sh_test = pd.concat(intput_sh_df,ignore_index=True,copy=False) \n",
    "\n",
    "\n",
    "# Do some things before testing on the frame\n",
    "#df_tr_test = pd.get_dummies(df_tr_test,columns=[\"track_is_daughter\",\"track_daughter\"],drop_first=True)\n",
    "df_sh_test[\"true_mu\"] = df_sh_test[\"matched_showers\"].abs() == 13\n",
    "df_sh_test[\"true_e\"] = df_sh_test[\"matched_showers\"] == 11\n",
    "\n",
    "columns_shower_map  = [\"shower_vtxdistance\",\"shower_dedx_w\",\"shower_maxangle\",\n",
    "                       \"shower_open_angle\",\"shower_pca\",\"shower_length\",\n",
    "                       \"shower_dedx_hits_w\",\"shower_hitsratio_w\",\"\",\n",
    "                       \"shower_theta\",\"shower_hits_w\",\"shower_energy_w\",\"\",\"lepton_E\",\"lepton_theta\"\n",
    "                      ]\n",
    "\n",
    "# Also require a reconstructed energy of at leact x Mev\n",
    "df_sh_test = df_sh_test[df_sh_test[\"shower_dedx_hits_w\"]>=min_dedx_hits]\n",
    "df_sh_test = df_sh_test[df_sh_test[\"shower_energy_w\"]>=min_reco_e]\n",
    "df_sh_test = df_sh_test[~df_sh_test[\"shower_start_z\"].between(z_dead_start,z_dead_end)]\n",
    "df_sh_test = df_sh_test[df_sh_test[\"matched_showers_energy\"]>0]\n",
    "df_sh_test = df_sh_test[df_sh_test[\"matched_showers_energy\"]<10]\n",
    "\n",
    "df_sh_cle = df_sh_test[df_sh_test[\"shower_cle\"]==1]\n",
    "df_sh_cle[\"\"]=0\n",
    "\n",
    "\n",
    "labels = [\"vertex distance\",r\"d$E$/d$x$ at start\",\"maximum object angle\",\n",
    "                       \"opening angle\",\"principal component\",\"length\",\n",
    "                       r\"#hits in first 4cm\",\"cluster/spacepoint hits\",\"\",\n",
    "                       r\"shower direction $\\theta$\",\"total hits\",\"reconstructed energy\",\"\",\"true energy\",r\"true lepton direction $\\theta$\"\n",
    "                      ]\n",
    "\n",
    "sns.heatmap(df_sh_cle[columns_shower_map].corr(),cmap=\"coolwarm\",xticklabels=labels,yticklabels=labels,vmin=-1, vmax=1,\n",
    "            cbar_kws={\"label\": \"correlation\"}\n",
    "           )\n",
    "\n",
    "plt.savefig((output_dir+\"shower_corr.pdf\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_test = [input_dir+\"nue_tune3/nue_tune3_track_1.pckl\",\n",
    "              input_dir+\"nue_tune3/nue_tune3_track_2.pckl\",\n",
    "              #input_dir+\"nue_tune3/nue_tune3_track_7.pckl\",\n",
    "              #input_dir+\"nue_tune3/nue_tune3_track_8.pckl\",\n",
    "              #input_dir+\"nue_tune3/nue_tune3_track_9.pckl\"\n",
    "              ]\n",
    "\n",
    "intput_tr_df = [ pd.read_pickle(x) for x in input_test]\n",
    "df_tr_test = pd.concat(intput_tr_df,ignore_index=True,copy=False) \n",
    "\n",
    "\n",
    "# Do some things before testing on the frame\n",
    "df_tr_test = pd.get_dummies(df_tr_test,columns=[\"track_is_daughter\",\"track_daughter\"],drop_first=True)\n",
    "df_tr_test[\"true_mu\"] = df_tr_test[\"matched_tracks\"].abs() == 13\n",
    "df_tr_test[\"true_e\"] = df_tr_test[\"matched_tracks\"] == 11\n",
    "\n",
    "columns_track_map  = [\"track_vtxdistance\",\"track_dedx_w\",\"track_maxangle\",\n",
    "                      \"predict_em\",\"track_daughter_1\",\n",
    "                       \"track_len\",\"track_dedx_hits_w\",\"track_hitsratio_w\",\"\",\n",
    "                       \"track_theta\",\"track_hits_w\",\"track_energy_w\",\"\",\"lepton_E\",\"lepton_theta\"\n",
    "                      ]\n",
    "\n",
    "# Also require a reconstructed energy of at leact x Mev\n",
    "df_tr_test = df_tr_test[df_tr_test[\"track_dedx_hits_w\"]>=min_dedx_hits]\n",
    "df_tr_test = df_tr_test[df_tr_test[\"track_energy_w\"]>=min_reco_e]\n",
    "df_tr_test = df_tr_test[~df_tr_test[\"track_start_z\"].between(z_dead_start,z_dead_end)]\n",
    "df_tr_test = df_tr_test[df_tr_test[\"matched_tracks_energy\"]>0]\n",
    "df_tr_test = df_tr_test[df_tr_test[\"matched_tracks_energy\"]<10]\n",
    "\n",
    "df_tr_cle = df_tr_test[df_tr_test[\"track_cle\"]==1] \n",
    "\n",
    "labels = [\"vertex distance\",r\"d$E$/d$x$ at start\",\"maximum object angle\",\n",
    "          \"Katherine's track ID\",\"has a shower daughter\",\n",
    "          \"length\",r\"#hits in first 4cm\",\"cluster/spacepoint hits\",\"\",\n",
    "          r\"track direction $\\theta$\",\"total hits\",\"reconstructed nergy\",\"\",\"true energy\",r\"true lepton direction $\\theta$\"\n",
    "          ]\n",
    "\n",
    "df_tr_cle = df_tr_test[\"track_cle\"]\n",
    "df_tr_test[\"\"]=0\n",
    "g = sns.heatmap(df_tr_test[columns_track_map].corr(),cmap=\"coolwarm\",xticklabels=labels,yticklabels=labels,vmin=-1, vmax=1,\n",
    "            cbar_kws={\"label\": \"correlation\"}\n",
    "           )\n",
    "#g.set_xticklabels(g.get_yticklabels(), rotation = 90,ha=\"center\")\n",
    "plt.savefig((output_dir+\"track_corr.pdf\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data MC plots Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# POT for the BNB nu test set file 0-3\n",
    "pot_nu = (\n",
    "      3.268803486357006e+20+\n",
    "      3.275377418388517e+20+\n",
    "      3.2636240240463466e+20+\n",
    "      3.2694485860610775e+20\n",
    "     )\n",
    "\n",
    "#TUNE3\n",
    "pot_nu = (3.835e+20)\n",
    "\n",
    "pot_bnb = 3.918e+19\n",
    "scale_ext= 0.157\n",
    "\n",
    "pid_list   = [[11],[-13,13],[111,22],[2212],[-211,211]]\n",
    "pid_labels = [r\"$e^-$\",r\"$\\mu^- / \\mu^+$\",r\"$\\gamma$\",\"proton\",r\"$\\pi^- / \\pi^+$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_nu = [#input_dir+\"nu_tune3/nu_tune3_track_0.pckl\",\n",
    "            #input_dir+\"nu_tune3/nu_tune3_track_1.pckl\",\n",
    "            input_dir+\"nu_tune3/nu_tune3_track_2.pckl\",\n",
    "            input_dir+\"nu_tune3/nu_tune3_track_3.pckl\",\n",
    "           ]\n",
    "\n",
    "input_nue = [#input_dir+\"nue_tune3/nue_tune3_track_5.pckl\",\n",
    "             #input_dir+\"nue_tune3/nue_tune3_track_6.pckl\",\n",
    "             #input_dir+\"nue_tune3/nue_tune3_track_7.pckl\",\n",
    "             input_dir+\"nue_tune3/nue_tune3_track_1.pckl\",\n",
    "             input_dir+\"nue_tune3/nue_tune3_track_2.pckl\"\n",
    "            ]\n",
    "\n",
    "intput_tr_df = [ pd.read_pickle(x) for x in input_nu]\n",
    "df_tr_nu  = pd.concat(intput_tr_df,ignore_index=True,copy=False) \n",
    "intput_tr_df = [ pd.read_pickle(x) for x in input_nue]\n",
    "df_tr_nue = pd.concat(intput_tr_df,ignore_index=True,copy=False) \n",
    "\n",
    "df_tr_bnb = pd.read_pickle(input_dir+\"bnb/bnb_track_9.pckl\")\n",
    "df_tr_bnbext = pd.read_pickle(input_dir+\"bnbext/bnbext_track_9.pckl\")\n",
    "\n",
    "df_tr_list = [df_tr_nu,df_tr_nue, df_tr_bnb, df_tr_bnbext]\n",
    "df_tr_ok_list = []\n",
    "for df in df_tr_list:\n",
    "    df = df[df[\"track_dedx_hits_w\"]>=min_dedx_hits]\n",
    "    df = df[df[\"track_energy_w\"]>=min_reco_e]\n",
    "    df = df[df[\"track_dedx_hits_w\"]>=min_dedx_hits]\n",
    "    df = df[~df[\"track_start_z\"].between(z_dead_start,z_dead_end)]\n",
    "    df = pd.get_dummies(df,columns=[\"track_is_daughter\",\"track_daughter\"],drop_first=True)\n",
    "    df = insertscores(df,columns_track_XGB,columns_track_XGB_mu,\"tr\")\n",
    "    df_tr_ok_list.append(df)\n",
    "\n",
    "df_tr_nu = df_tr_ok_list[0]\n",
    "df_tr_nue = df_tr_ok_list[1]\n",
    "df_tr_bnb = df_tr_ok_list[2]\n",
    "df_tr_bnbext = df_tr_ok_list[3]\n",
    "\n",
    "df_tr_all = pd.concat([df_tr_nu,df_tr_nue],ignore_index=True)\n",
    "\n",
    "df_tr_nu[\"weight\"]=df_tr_nu[\"bnbweight\"]*pot_bnb/pot_nu\n",
    "df_tr_bnb[\"weight\"]=1\n",
    "df_tr_bnbext[\"weight\"]=scale_ext\n",
    "\n",
    "\n",
    "columns_track_map  = [\"track_vtxdistance\",\"track_dedx_w\",\"track_maxangle\",\n",
    "                      \"predict_em\",\"predict_cos\",\"predict_mu\",\"predict_p\",\"predict_pi\",\"track_daughter_1\",\n",
    "                      \"track_len\",\"track_dedx_hits_w\",\"track_hitsratio_w\",\"track_spacepoint_dqdx_ratio\",\n",
    "                      \"track_theta\",\"track_hits_w\",\"track_energy_w\",\n",
    "                      \"tr_mu\",\"tr_e\",\"tr_cle\",\"track_bdt_precut\"\n",
    "                      ]\n",
    "\n",
    "labels = [\"Vertex distance [cm]\",r\"d$E$/d$x$ at start [MeV/cm]\",\"Maximum object angle\",\n",
    "          \"Katherine's track ID (EM)\",\"Katherine's track ID (cosmic)\",\"Katherine's track ID (muon)\",\"Katherine's track ID (proton)\",\"Katherine's track ID (pion)\",\"Track has a shower daughter\",\n",
    "          \"Length [cm]\",r\"#hits in first 4cm\",\"Ratio cluster/spacepoint hits\",r\"Ratio d$E$/d$x$ in first and second half\",\n",
    "          r\"Track direction $\\theta$\",\"Total hits (collection plane)\",\"Reconstructed energy [GeV]\",\n",
    "          \"Muon matched track score\",\"Electron matched track score\",\n",
    "          \"Closest electron matched track score\",\"Track_bdt_precut\"\n",
    "          ]\n",
    "\n",
    "x_axis_max = [10,6,1,1,1,1, 1 ,1,1,150,17.75,1,5, 3.14,600,1, 1,1,1,1]\n",
    "x_axis_min = [0 ,0,-1,0,0,0 ,0,0,0,0  ,-0.25,0,0,0     ,0   ,0, 0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x_axis,x_lab,min_x,max_x in zip(columns_track_map,labels,x_axis_min,x_axis_max):\n",
    "    \n",
    "    fig,ax=plt.subplots(ncols=2,figsize=(6*gr,3.5),sharex=True)\n",
    "    N = 36\n",
    "    max_y = 38000\n",
    "    binwidth=(max_x-min_x)/N\n",
    "    binhalf=binwidth/2\n",
    "\n",
    "    # MC+BNBext\n",
    "    df_stacked = [df_tr_bnbext,df_tr_nu]\n",
    "    lab_stacked = [\"BNBext\",\"MC\"]\n",
    "    lower_total = 0\n",
    "    \n",
    "    for df_stack,lab in zip(df_stacked,lab_stacked):\n",
    "        df_stack = df_stack[df_stack[x_axis].between(min_x,max_x)][[x_axis,\"weight\"]]\n",
    "        lower,_,_ = ax[0].hist(df_stack[x_axis],bins=N,weights=df_stack[\"weight\"], range=(min_x,max_x), stacked=False, fill=True,label=lab,bottom=lower_total,alpha=0.8)\n",
    "        lower_total+=lower\n",
    "\n",
    "    #Data\n",
    "    data_bnb   = df_tr_bnb[df_tr_bnb[x_axis].between(min_x,max_x)][[x_axis,\"weight\"]]\n",
    "    bins,edges = np.histogram(data_bnb[x_axis],bins=N,weights=data_bnb[\"weight\"],range=(min_x,max_x))\n",
    "    ax[0].errorbar(edges[:-1]+binhalf, bins, xerr=binhalf, yerr=np.sqrt(bins),alpha=1.0, color= \"k\",fmt=\".\",label=\"BNB (3.9e19 POT)\")\n",
    "    \n",
    "    ax[0].set_ylabel(\"Number of tracks ber bin\")\n",
    "    ax[0].set_xlabel(x_lab)\n",
    "    ax[0].set_xlim(min_x,max_x)\n",
    "    ax[0].legend()\n",
    "    ax[0].set_title(\"Data/MC comparison\")\n",
    "    \n",
    "    for pid,pid_lab in zip(pid_list,pid_labels):\n",
    "        ax[1].hist(df_tr_all[df_tr_all[\"matched_tracks\"].isin(pid)][x_axis],bins=N,alpha=1.0,range=(min_x,max_x),density=True,label=pid_lab,histtype=\"step\", stacked=False, fill=False)\n",
    "    ax[1].set_xlabel(x_lab)\n",
    "    ax[1].set_ylabel(\"Area normalised\")\n",
    "    ax[1].legend(loc=\"best\")\n",
    "    ax[1].set_title(\"MC truth matched\")\n",
    "    \n",
    "    if \"closest\" in x_lab:\n",
    "        ax[0].set_ylim(0,50)\n",
    "        \n",
    "    if \"ID\" in x_lab:\n",
    "        ax[0].set_ylim(0,200)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig((output_dir+x_axis+\".pdf\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data MC plots Shower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_nu = [#input_dir+\"nu_tune3/nu_tune3_shower_0.pckl\",\n",
    "            #input_dir+\"nu_tune3/nu_tune3_shower_1.pckl\",\n",
    "            input_dir+\"nu_tune3/nu_tune3_shower_2.pckl\",\n",
    "            input_dir+\"nu_tune3/nu_tune3_shower_3.pckl\",\n",
    "           ]\n",
    "\n",
    "input_nue = [#input_dir+\"nue_tune3/nue_tune3_shower_5.pckl\",\n",
    "             #input_dir+\"nue_tune3/nue_tune3_shower_6.pckl\",\n",
    "             #input_dir+\"nue_tune3/nue_tune3_shower_7.pckl\",\n",
    "             input_dir+\"nue_tune3/nue_tune3_shower_1.pckl\",\n",
    "             input_dir+\"nue_tune3/nue_tune3_shower_2.pckl\"\n",
    "            ]\n",
    "\n",
    "\n",
    "intput_sh_df = [ pd.read_pickle(x) for x in input_nu]\n",
    "df_sh_nu  = pd.concat(intput_sh_df,ignore_index=True,copy=False) \n",
    "intput_sh_df = [ pd.read_pickle(x) for x in input_nue]\n",
    "df_sh_nue = pd.concat(intput_sh_df,ignore_index=True,copy=False) \n",
    "\n",
    "df_sh_bnb = pd.read_pickle(input_dir+\"bnb/bnb_shower_9.pckl\")\n",
    "df_sh_bnbext = pd.read_pickle(input_dir+\"bnbext/bnbext_shower_9.pckl\")\n",
    "\n",
    "df_sh_list = [df_sh_nu,df_sh_nue, df_sh_bnb, df_sh_bnbext]\n",
    "df_sh_ok_list = []\n",
    "for df in df_sh_list:\n",
    "    df = df[df[\"shower_dedx_hits_w\"]>=min_dedx_hits]\n",
    "    df = df[df[\"shower_energy_w\"]>=min_reco_e]\n",
    "    df = df[df[\"shower_dedx_hits_w\"]>=min_dedx_hits]\n",
    "    df = df[~df[\"shower_start_z\"].between(z_dead_start,z_dead_end)]\n",
    "    df = pd.get_dummies(df,columns=[\"shower_is_daughter\",\"shower_daughter\"],drop_first=True)\n",
    "    df = insertscores(df,columns_shower_XGB,columns_shower_XGB_mu,\"sh\")\n",
    "    df_sh_ok_list.append(df)\n",
    "\n",
    "df_sh_nu = df_sh_ok_list[0]\n",
    "df_sh_nue = df_sh_ok_list[1]\n",
    "df_sh_bnb = df_sh_ok_list[2]\n",
    "df_sh_bnbext = df_sh_ok_list[3]\n",
    "\n",
    "df_sh_all = pd.concat([df_sh_nu,df_sh_nue],ignore_index=True)\n",
    "\n",
    "df_sh_nu[\"weight\"]=df_sh_nu[\"bnbweight\"]*pot_bnb/pot_nu\n",
    "df_sh_bnb[\"weight\"]=1\n",
    "df_sh_bnbext[\"bnbweight\"]=1\n",
    "df_sh_bnbext[\"weight\"]=scale_ext\n",
    "\n",
    "columns_shower_map  = [\"shower_vtxdistance\",\"shower_dedx_w\",\"shower_maxangle\",\n",
    "                       \"shower_open_angle\",\"shower_pca\",\"shower_length\",\n",
    "                       \"shower_dedx_hits_w\",\"shower_hitsratio_w\",\"n_showers\",\n",
    "                       \"shower_theta\",\"shower_hits_w\",\"shower_energy_w\",\n",
    "                       \"sh_mu\",\"sh_e\",\"sh_cle\",\"sh_cle_lee\"\n",
    "                      ]\n",
    "\n",
    "labels = [\"Vertex distance [cm]\",r\"d$E/$d$x$ at start [MeV/cm]\",\"Maximum object angle (cosine)\",\n",
    "          \"Opening angle [rad]\",\"Principal component of clusters\",\"Length [cm]\",\n",
    "          r\"Number of cluster hits in first 4cm\",\"Ratio of number cluster/spacepoint hits\",\"Number of showers in hierarchy\",\n",
    "          r\"Shower direction $\\theta$ [rad]\",\"Total hits\",\"Reconstructed energy [GeV]\",\n",
    "          \"Muon matched shower score\",\"Electron matched shower score\",\n",
    "          \"Closest electron matched shower score (NOT LEE)\",\"Closest electron matched shower score\"\n",
    "         ]\n",
    "\n",
    "x_axis_max = [10,6,1 ,3.14/4,1,200,17.75,1, 8.5,3.14,600,1, 1,1,1,1]\n",
    "x_axis_min = [0 ,0,-1,0     ,0.75,0  ,-0.25,0,-0.5 ,0     ,0   ,0, 0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x_axis,x_lab,min_x,max_x in zip(columns_shower_map,labels,x_axis_min,x_axis_max):\n",
    "    \n",
    "    if x_axis==\"sh_cle_lee\":\n",
    "        fig,ax=plt.subplots(ncols=1,nrows=2,figsize=(5,6),sharex=True)\n",
    "    else:\n",
    "        fig,ax=plt.subplots(ncols=2,nrows=1,figsize=(6*gr,3.5),sharex=True)\n",
    "        \n",
    "    N = 36\n",
    "    max_y = 38000\n",
    "    binwidth=(max_x-min_x)/N\n",
    "    binhalf=binwidth/2\n",
    "\n",
    "    # MC+BNBext\n",
    "    df_stacked = [df_sh_bnbext,df_sh_nu]\n",
    "    scale_stacked = [scale_ext, pot_bnb/pot_nu]\n",
    "    lab_stacked = [\"BNBext\",\"MC\"]\n",
    "    lower_total = 0\n",
    "    err = [0] * N\n",
    "    \n",
    "    for df_stack,lab,scale in zip(df_stacked,lab_stacked,scale_stacked):\n",
    "        #print(df_stack.columns)\n",
    "        df_stack = df_stack[df_stack[x_axis].between(min_x,max_x)][[x_axis,\"weight\",\"bnbweight\"]]\n",
    "        lower,edges,_ = ax[0].hist(df_stack[x_axis],bins=N,weights=df_stack[\"weight\"], range=(min_x,max_x), stacked=False, fill=True,label=lab,bottom=lower_total,alpha=0.8)\n",
    "        err += hist_bin_uncertainty(df_stack[x_axis].tolist(),df_stack[\"bnbweight\"].tolist(),edges)*scale\n",
    "        lower_total+=lower\n",
    "        \n",
    "    for this_err,entry,bin_start in zip(err,lower_total,edges[:-1]):\n",
    "        ax[0].add_patch(patches.Rectangle( (bin_start, entry-this_err), binwidth, this_err*2, hatch=\"\\\\\\\\\\\\\\\\\\\\\",Fill=False, linewidth=0,alpha=0.4))\n",
    "\n",
    "    #Data\n",
    "    data_bnb   = df_sh_bnb[df_sh_bnb[x_axis].between(min_x,max_x)][[x_axis,\"weight\"]]\n",
    "    bins,edges = np.histogram(data_bnb[x_axis],bins=N,weights=data_bnb[\"weight\"],range=(min_x,max_x))\n",
    "    ax[0].errorbar(edges[:-1]+binhalf, bins, xerr=binhalf, yerr=np.sqrt(bins),alpha=1.0, color= \"k\",fmt=\".\",label=\"BNB (3.9e19 POT)\")\n",
    "    \n",
    "    ax[0].set_ylabel(\"Number of showers ber bin\")\n",
    "    ax[0].set_xlabel(x_lab)\n",
    "    ax[0].set_xlim(min_x,max_x)\n",
    "    ax[0].legend(loc=\"best\")\n",
    "    ax[0].set_title(\"Data/MC comparison\")\n",
    "    \n",
    "    data = df_sh_all[(df_sh_all[\"shower_cle\"]==1) & (df_sh_all[\"matched_showers_energy\"]>-0.5)][x_axis]\n",
    "    ax[1].hist(data,bins=N,alpha=1.0,range=(min_x,max_x),density=True,label=r\"$e^-$\",histtype=\"step\", stacked=False, fill=False)\n",
    "    \n",
    "    for pid,pid_lab in zip(pid_list[1:],pid_labels[1:]):\n",
    "        data = df_sh_all[df_sh_all[\"matched_showers\"].isin(pid)][x_axis]\n",
    "        ax[1].hist(data,bins=N,alpha=1.0,range=(min_x,max_x),density=True,label=pid_lab,histtype=\"step\", stacked=False, fill=False)\n",
    "    \n",
    "    #data = df_sh_all[(df_sh_all[\"shower_cle\"]==1) & (df_sh_all[\"matched_showers_energy\"]<0.5)][x_axis]\n",
    "    #ax[1].hist(data,bins=N,alpha=1.0,range=(min_x,max_x),density=True,label=r\"closest $e$, <500MeV\",histtype=\"step\", stacked=False, fill=False)\n",
    "    \n",
    "    \n",
    "    ax[1].set_xlabel(x_lab)\n",
    "    ax[1].set_ylabel(\"Area normalised\")\n",
    "    \n",
    "    \n",
    "    ax[1].set_title(\"MC truth matched\")\n",
    "    \n",
    "    if \"closest\" in x_lab:\n",
    "        ax[0].set_ylim(0,50)\n",
    "    if max_x==1 or x_axis == \"shower_dedx_hits_w\":\n",
    "        ax[1].legend(loc=\"upper center\")\n",
    "    else:\n",
    "        ax[1].legend(loc=\"best\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig((output_dir+x_axis+\".pdf\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "df_plot = df_sh_nue[df_sh_nue[\"shower_cle\"]==1]\n",
    "h = sns.jointplot(df_plot[\"sh_cle_lee\"],df_plot[\"lepton_E\"],kind=\"kde\",stat_func=None,n_levels=10,ylim=(0.2,2),size=4)\n",
    "\n",
    "h.ax_joint.text(0,1.5,\"correlation = 0.05\")\n",
    "h.set_axis_labels(\"Closest electron matched shower score\", \"Electron true energy [GeV]\")\n",
    "\n",
    "plt.savefig(output_dir+\"joint_shower.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Preselected data events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sh_bnb[ ((df_sh_bnb[\"run\"]==5328) & (df_sh_bnb[\"subrun\"]== 30) & (df_sh_bnb[\"event\"]==1515)) |\n",
    "        ((df_sh_bnb[\"run\"]==5513) & (df_sh_bnb[\"subrun\"]==  0) & (df_sh_bnb[\"event\"]==  31)) |\n",
    "        ((df_sh_bnb[\"run\"]==5187) & (df_sh_bnb[\"subrun\"]==182) & (df_sh_bnb[\"event\"]==9135)) |\n",
    "        ((df_sh_bnb[\"run\"]==5508) & (df_sh_bnb[\"subrun\"]== 90) & (df_sh_bnb[\"event\"]==4517)) |\n",
    "        ((df_sh_bnb[\"run\"]==5761) & (df_sh_bnb[\"subrun\"]== 11) & (df_sh_bnb[\"event\"]== 582)) |\n",
    "        ((df_sh_bnb[\"run\"]==5914) & (df_sh_bnb[\"subrun\"]== 69) & (df_sh_bnb[\"event\"]==3463)) |\n",
    "        ((df_sh_bnb[\"run\"]==5938) & (df_sh_bnb[\"subrun\"]== 83) & (df_sh_bnb[\"event\"]==4196))\n",
    "      ][[\"sh_cle\",\"sh_cle_lee\",\"sh_e\",\"sh_mu\",\"subrun\",\"event\",\"n_showers\",\"n_tracks\",\"shower_energy_w\",\"shower_is_daughter_2\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tr_bnb[ ((df_tr_bnb[\"run\"]==5328) & (df_tr_bnb[\"subrun\"]== 30) & (df_tr_bnb[\"event\"]==1515)) |\n",
    "        ((df_tr_bnb[\"run\"]==5513) & (df_tr_bnb[\"subrun\"]==  0) & (df_tr_bnb[\"event\"]==  31)) |\n",
    "        ((df_tr_bnb[\"run\"]==5187) & (df_tr_bnb[\"subrun\"]==182) & (df_tr_bnb[\"event\"]==9135)) |\n",
    "        ((df_tr_bnb[\"run\"]==5508) & (df_tr_bnb[\"subrun\"]== 90) & (df_tr_bnb[\"event\"]==4517)) |\n",
    "        ((df_tr_bnb[\"run\"]==5761) & (df_tr_bnb[\"subrun\"]== 11) & (df_tr_bnb[\"event\"]== 582)) |\n",
    "        ((df_tr_bnb[\"run\"]==5914) & (df_tr_bnb[\"subrun\"]== 69) & (df_tr_bnb[\"event\"]==3463)) |\n",
    "        ((df_tr_bnb[\"run\"]==5938) & (df_tr_bnb[\"subrun\"]== 83) & (df_tr_bnb[\"event\"]==4196))\n",
    "      ][[\"tr_cle\",\"tr_e\",\"tr_mu\",\"subrun\",\"event\",\"n_showers\",\"n_tracks\",\"track_daughter_1\",\"track_energy_w\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
