{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEE Analyzer notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes in the output directory of the jobs and convert it into a more flat pandas dataframe. \n",
    "Data from the root files will be partially processed to fields that are convenient to plot.\n",
    "The resulting dataframe will be pickled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from root_pandas import read_root\n",
    "from collections import OrderedDict\n",
    "\n",
    "from helpfunction import safely_reduce_dtype,reduce_mem_usage,sciNot,CheckBorderTPC,CheckBorderFixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999\n",
    "gr      = 1.618\n",
    "nan     = -2147483648\n",
    "min_root_size = 20000 # Skip root files smaller than x bytes\n",
    "\n",
    "mass_p= 0.93827 #GeV\n",
    "mass_e= 0.00511 #GeV\n",
    "\n",
    "# LAr EM showers\n",
    "R_moliere =  9.5 # cm\n",
    "X_o       = 13.9 # cm\n",
    "E_c       = 0.035# GeV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Which plane do we want to use:\n",
    "plane = 2 # collection plane only\n",
    "\n",
    "# Fiducial volume borders in x,y,z:\n",
    "fid_arr= [[10,10],[20,20],[10,50]]\n",
    "# Fiducial volume for the end points of tracks\n",
    "fid_min = 10\n",
    "# Percentage cut for shower containment\n",
    "sh_cont_percent = .75\n",
    "\n",
    "# Minimum reconstructable energies:\n",
    "min_e = 0.02+mass_e # 20MeV\n",
    "min_p = 0.04+mass_p # 40MeV\n",
    "\n",
    "# Flat columns we want to copy from the original dataframe:\n",
    "flat_columns = ['event','subrun','run','nu_pdg','nu_E','true_vx_sce','true_vy_sce','true_vz_sce',\n",
    "                'distance','category','vx','vy','vz','bnbweight','passed']\n",
    "\n",
    "vec_columns = ['shower_open_angle','shower_length','shower_start_x','shower_start_y','shower_start_z',\n",
    "              'shower_dir_x','shower_dir_y','shower_dir_z','shower_pca',\n",
    "\n",
    "              'track_start_x','track_start_y','track_start_z','track_end_x','track_end_y','track_end_z',\n",
    "              'track_dir_x','track_dir_y','track_dir_z','track_pca',\n",
    "              'predict_em','predict_mu','predict_cos','predict_pi','predict_p',\n",
    "\n",
    "              'nu_daughters_pdg','nu_daughters_E','nu_daughters_px','nu_daughters_py','nu_daughters_pz',\n",
    "              'nu_daughters_endx','nu_daughters_endy','nu_daughters_endz',\n",
    "              'true_shower_pdg','true_shower_x_sce','true_shower_y_sce','true_shower_z_sce','true_shower_depE'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 valid ROOT files collected.\n"
     ]
    }
   ],
   "source": [
    "# Input directory\n",
    "# Can be on gpvms, example: '/run/user/1000/gvfs/sftp:host=uboonegpvm02.fnal.gov,user=wvdp/uboone/data/users/wvdp/v06_26_01_10/data_bnb_a_1e0p/*/*.root'\n",
    "# Local will be faster, avoid using pnfs scratch\n",
    "inputlist = []\n",
    "inputlist += glob.glob('/home/wouter/Templates/intime_test/*.root')\n",
    "#inputlist += glob.glob('/home/wouter/Templates/data_bnb_b_1e0p/*/*.root')\n",
    "\n",
    "filelist  = []\n",
    "for fname in inputlist:\n",
    "    if (os.stat(fname).st_size)<min_root_size:\n",
    "            print('File',fname,'was corrupt. Size:',os.stat(fname).st_size/1000, 'kb, skipping to next file.')\n",
    "    else:\n",
    "        filelist.append(fname)\n",
    "print(len(filelist),'valid ROOT files collected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Signal Definition 1e0p \n",
    "def true_thresholds_1e0p(row):\n",
    "    if CheckBorderTPC(row['true_vx_sce'],row['true_vy_sce'],row['true_vz_sce'],fid_arr):\n",
    "        passed_e=False\n",
    "        for pdg,E in zip(row[\"nu_daughters_pdg\"],row[\"nu_daughters_E\"]):\n",
    "            if pdg==11 and E>min_e:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def KatrinBDT(row):\n",
    "    if np.all(row['predict_p']>0.001):\n",
    "        if np.all(row['predict_mu']<0.6):\n",
    "            if np.all(row['predict_cos']<0.6):\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Verifies if the event passed the flash precuts.\n",
    "def FlashPrecut(row):\n",
    "    flash_ok = False\n",
    "    t_start = 3.2\n",
    "    t_end   = t_start+1.6\n",
    "    min_PE  = 50\n",
    "\n",
    "    for time,PE in zip(row['flash_time'],row['flash_PE']):\n",
    "        if time>t_start and time<t_end and PE>min_PE:\n",
    "            flash_ok = True\n",
    "    return pd.Series({\"flash_precut\": flash_ok}) \n",
    "\n",
    "\n",
    "\n",
    "# Reconstructed energy using collection plane\n",
    "def CalcRecoE(row):\n",
    "    reco_energy = 0\n",
    "    total_nhits = 0 # sum over all the planes\n",
    "    shower_nhits = np.zeros(row['n_showers']) \n",
    "    shower_energy = np.zeros(row['n_showers'])\n",
    "    track_nhits = np.zeros(row['n_tracks'])\n",
    "    track_energy = np.zeros(row['n_tracks'])\n",
    "    \n",
    "    for tr, tr_E, nhits in zip(range(row['n_tracks']),row['track_energy_hits'],row[\"track_nhits\"]):\n",
    "        reco_energy+=tr_E[plane]\n",
    "        track_nhits[tr] = int(nhits[plane])\n",
    "        track_energy[tr] = tr_E[plane]\n",
    "        total_nhits+=int(sum(nhits))\n",
    "        \n",
    "    for sh, sh_E, nhits in zip(range(row['n_showers']),row['shower_energy'],row[\"shower_nhits\"]):\n",
    "        reco_energy+=sh_E[plane]\n",
    "        shower_nhits[sh] = int(nhits[plane])\n",
    "        shower_energy[sh] = sh_E[plane]\n",
    "        total_nhits+=int(sum(nhits))\n",
    "        \n",
    "    return pd.Series({\"reconstructed_energy\": reco_energy, \"total_nhits\": total_nhits,\n",
    "                      \"shower_nhits\": shower_nhits, \"shower_energy\": shower_energy,\n",
    "                      \"track_nhits\": track_nhits, \"track_energy\": track_energy})\n",
    "\n",
    "\n",
    "\n",
    "# Add info about the pandora particle hierarchy\n",
    "def DaughterInfo(row):\n",
    "    nu_shower_ids, nu_track_ids                = row['nu_shower_ids'],row['nu_track_ids']\n",
    "    nu_shower_daughters, nu_track_daughters    = list(row['nu_shower_daughters']),list(row['nu_track_daughters'])\n",
    "\n",
    "    showerdaughter = []\n",
    "    for sh in nu_shower_daughters:\n",
    "        if len(sh)==0:\n",
    "            showerdaughter.append(0)\n",
    "        elif len(sh)==1:\n",
    "            if sh[0] in nu_shower_ids:\n",
    "                showerdaughter.append(1)\n",
    "            elif sh[0] in nu_track_ids:\n",
    "                showerdaughter.append(2)\n",
    "        else:\n",
    "            showerdaughter.append(3)\n",
    "            \n",
    "    trackdaughter = []\n",
    "    for tr in nu_track_daughters:\n",
    "        if len(tr)==0:\n",
    "            trackdaughter.append(0)\n",
    "        elif len(tr)==1:\n",
    "            if tr[0] in nu_shower_ids:\n",
    "                trackdaughter.append(1)\n",
    "            elif tr[0] in nu_track_ids:\n",
    "                trackdaughter.append(2)\n",
    "        else:\n",
    "            trackdaughter.append(3)\n",
    "    return pd.Series({\"shower_daughter\": showerdaughter, \"track_daughter\": trackdaughter})     \n",
    "\n",
    "\n",
    "\n",
    "# Calculates the true end point for electron showers, for 95% of energy\n",
    "def showerTrueEnd(row):\n",
    "    if 11 not in row['nu_daughters_pdg']:\n",
    "        return pd.Series({\"true_shower_endx\": -999.0, \"true_shower_endy\": -999.0, \"true_shower_endz\": -999.0,\n",
    "                      \"true_shower_tmax_x\": -999.0, \"true_shower_tmax_y\": -999.0, \"true_shower_tmax_z\": -999.0})\n",
    "    i_daughter = np.nonzero(row['nu_daughters_pdg']==11)\n",
    "    if len(i_daughter[0])>1:\n",
    "        print('More than 1 true electron daughter')\n",
    "    i_daughter = i_daughter[0][0]\n",
    "    \n",
    "    E_ratio = (row['nu_daughters_E'][i_daughter])/E_c\n",
    "    t_max = np.log(E_ratio)-1.0\n",
    "    length = (t_max+0.08*18+9.6)*X_o\n",
    "    #print('E_ratio',E_ratio,'E',row['nu_daughters_E'][i_daughter],' t_max',t_max,'length',length)\n",
    "    direction = np.array([row['nu_daughters_px'][i_daughter],row['nu_daughters_py'][i_daughter],row['nu_daughters_pz'][i_daughter]])\n",
    "    true_shower_start = np.array([row['nu_daughters_vx'][i_daughter],row['nu_daughters_vy'][i_daughter],row['nu_daughters_vz'][i_daughter]])\n",
    "    true_shower_end = true_shower_start+length*direction/np.linalg.norm(direction)\n",
    "    true_shower_tmax = true_shower_start+(t_max*X_o)*direction/np.linalg.norm(direction)\n",
    "    \n",
    "    return pd.Series({\"true_shower_endx\": true_shower_end[0], \"true_shower_endy\": true_shower_end[1], \"true_shower_endz\": true_shower_end[2],\n",
    "                      \"true_shower_tmax_x\": true_shower_tmax[0], \"true_shower_tmax_y\": true_shower_tmax[1], \"true_shower_tmax_z\": true_shower_tmax[2]})\n",
    "\n",
    "\n",
    "\n",
    "# Calculates the percentage of sps inside the fiducial volume and the percentage of deposited collection plane charge\n",
    "def ContainedRatio(row):\n",
    "    d=0.01\n",
    "    n=0.0\n",
    "    \n",
    "    for x,y,z,q in zip(row['shower_sp_x'],row['shower_sp_y'],row['shower_sp_z'],row['shower_sp_int']):\n",
    "        d+=q\n",
    "        if CheckBorderTPC(x,y,z,fid_arr):\n",
    "            n+=q\n",
    "\n",
    "    return pd.Series({\"shower_containment_q\": n/d}) \n",
    "\n",
    "\n",
    "\n",
    "def CC_daughter_E(row):\n",
    "    CC_daughter_i = np.nonzero(np.in1d(row['nu_daughters_pdg'], [11,-11,13,-13]))[0]\n",
    "    CC_daughter_E = -1\n",
    "    if len(CC_daughter_i)>0:\n",
    "        if len(CC_daughter_i)>2:\n",
    "            'Multiple electron/muon daughters found!'\n",
    "        else:      \n",
    "            CC_daughter_E = row['nu_daughters_E'][CC_daughter_i[0]]\n",
    "    return pd.Series({\"CC_daughter_E\": CC_daughter_E})  \n",
    "\n",
    "\n",
    "\n",
    "# Returns the ratio of collection charge of the first part and the second part of the summed shower.\n",
    "def ShowerChargeProfile(row):\n",
    "    x,y,z = row['vx'],row['vy'],row['vz']\n",
    "    sps_x_arr,sps_y_arr,sps_z_arr,sps_int_arr = row['shower_sp_x'],row['shower_sp_y'],row['shower_sp_z'],row['shower_sp_int']\n",
    "    \n",
    "    center= np.array([0.0,0.0,0.0])\n",
    "    total_Q = 0.0\n",
    "    for sps_x,sps_y,sps_z,sps_int in zip(sps_x_arr,sps_y_arr,sps_z_arr,sps_int_arr):\n",
    "        center+=np.array([sps_x,sps_y,sps_z])*sps_int\n",
    "        total_Q+=sps_int\n",
    "    center/=total_Q\n",
    "    norm = (center-np.array([x,y,z])) / np.linalg.norm(center-np.array([x,y,z]))\n",
    "    \n",
    "    distance = []\n",
    "    for sps_x,sps_y,sps_z in zip(sps_x_arr,sps_y_arr,sps_z_arr):\n",
    "        distance.append( np.dot([sps_x-x,sps_y-y,sps_z-z],norm) )\n",
    "        \n",
    "    y,x = np.histogram( distance, weights = sps_int_arr )\n",
    "    l = len(y)/2\n",
    "    return pd.Series({\"shower_sp_profile\": np.mean(y[:l])/np.mean(y[-l:])})  \n",
    "\n",
    "\n",
    "# Returns the dedx and the number of hits it had to compute this.\n",
    "def CalcDedx(row):\n",
    "    shower_dedx_hits = np.zeros(row['n_showers']) \n",
    "    shower_dedx      = np.zeros(row['n_showers'])\n",
    "    shower_dedx_sum  = np.zeros(row['n_showers']) \n",
    "    \n",
    "    track_dedx_hits  = np.zeros(row['n_tracks'])\n",
    "    track_dedx       = np.zeros(row['n_tracks'])\n",
    "    track_dedx_sum   = np.zeros(row['n_tracks'])\n",
    "    \n",
    "    \n",
    "    for tr, tr_E, nhits in zip(range(row['n_tracks']),row['track_dEdx'],row[\"track_dEdx_hits\"]):\n",
    "        track_dedx_hits[tr] = len(nhits)\n",
    "        track_dedx_sum[tr] += sum(nhits)\n",
    "        track_dedx[tr]      = tr_E[plane]\n",
    "        \n",
    "    for sh, sh_E, nhits in zip(range(row['n_showers']),row['shower_dEdx'],row[\"shower_dEdx_hits\"]):\n",
    "        shower_dedx_hits[sh] = len(nhits)\n",
    "        shower_dedx_sum[sh] += sum(nhits)\n",
    "        shower_dedx[sh]      = sh_E[plane]\n",
    "        \n",
    "    shower_dedx_sum/=row['n_showers']\n",
    "    track_dedx_sum/=row['n_tracks']\n",
    "    \n",
    "    return pd.Series({\"shower_dedx_hits\": shower_dedx_hits, \"shower_dedx\": shower_dedx, \"shower_dedx_avg\": shower_dedx_sum,\n",
    "                      \"track_dedx_hits\": track_dedx_hits, \"track_dedx\": track_dedx, \"track_dedx_avg\": track_dedx_sum})\n",
    "\n",
    "def OpticalInfo(row):\n",
    "    flash_PE=0\n",
    "    flash_time=0\n",
    "    if np.any(row['flash_passed']!=-1):\n",
    "        flash_PE = row['flash_PE'][np.max(row['flash_passed'])]\n",
    "        flash_time = row['flash_time'][np.max(row['flash_passed'])]\n",
    "    return pd.Series({\"flash_time\": flash_time, \"flash_PE\": flash_PE})\n",
    "\n",
    "def MatchedCleanup(row):\n",
    "    matched_tracks= row['matched_tracks']\n",
    "    print (row['matched_tracks'])\n",
    "    matched_tracks[row['matched_tracks']==-2147483648] = 0\n",
    "    \n",
    "    matched_tracks_energy= row['matched_tracks_energy']\n",
    "    matched_tracks_energy[matched_tracks_energy<-1] = 0\n",
    "    \n",
    "    matched_showers= row['matched_showers']\n",
    "    matched_showers[row['matched_showers']==-2147483648] = 0\n",
    "    \n",
    "    matched_showers_energy= row['matched_showers_energy']\n",
    "    matched_showers_energy[matched_showers_energy<-1] = 0\n",
    "    \n",
    "    return pd.Series({\"matched_tracks\": matched_tracks, \"matched_tracks_energy\": matched_tracks_energy,\n",
    "                      \"matched_showers\": matched_showers, \"matched_showers_energy\": matched_showers_energy})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection & Features dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BNB $\\nu$ + cosmics \n",
    "\n",
    "\n",
    "selection: We want to keep only the passed events but no further cuts on truth information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selection uses and ordered dict\n",
    "Nu_select_true = OrderedDict([])\n",
    "Nu_select_reco = OrderedDict([(\"Passed analyzer selection\", lambda x: x['passed']==1),\n",
    "                              (\"Katrin BDT anti-muon cuts\", KatrinBDT),\n",
    "                              ('Reco vtx in fidVol', lambda row: CheckBorderTPC(row['vx'],row['vy'],row['vz'],fid_arr))\n",
    "                             ])\n",
    "\n",
    "# Features uses a list of functions\n",
    "Nu_feature_list =[DaughterInfo, ContainedRatio, ShowerChargeProfile, CalcRecoE, CalcDedx, OpticalInfo,\n",
    "                 CC_daughter_E, showerTrueEnd, MatchedCleanup] # The last row used true info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BNB $\\nu_e$ intrinsic + cosmics \n",
    "\n",
    "\n",
    "selection: We want to do an efficiency plot, therefore we will need to have the signal definition selection. Non passed events need also to be filtered on that requirement before they are saved. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selection uses and ordered dict\n",
    "Nue_select_true = OrderedDict([('Signal Definition 1e0p',true_thresholds_1e0p)])\n",
    "Nue_select_reco = OrderedDict([(\"Passed analyzer selection\", lambda x: x['passed']==1),\n",
    "                               ('Reco vtx in fidVol', lambda row: CheckBorderTPC(row['vx'],row['vy'],row['vz'],fid_arr))\n",
    "                              ])\n",
    "\n",
    "# Features uses a list of functions\n",
    "Nue_feature_list =[DaughterInfo, ContainedRatio, ShowerChargeProfile, CalcRecoE, CalcDedx, OpticalInfo,\n",
    "                 CC_daughter_E, showerTrueEnd, MatchedCleanup] # The last row used true info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-time cosmics \n",
    "\n",
    "\n",
    "selection: Just passed events, no truth features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selection uses and ordered dict\n",
    "Intime_select_true = OrderedDict([])\n",
    "Intime_select_reco = OrderedDict([(\"Passed analyzer selection\", lambda x: x['passed']==1),\n",
    "                              ('Reco vtx in fidVol', lambda row: CheckBorderTPC(row['vx'],row['vy'],row['vz'],fid_arr))\n",
    "                             ])\n",
    "\n",
    "# Features uses a list of functions\n",
    "Intime_feature_list =[DaughterInfo, ContainedRatio, ShowerChargeProfile, CalcRecoE, CalcDedx, OpticalInfo, MatchedCleanup]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BNB ext or BNB data samples\n",
    "\n",
    "\n",
    "selection: we only want to keep passed events \n",
    "\n",
    "\n",
    "We need to be carefull not adding features that depend on truth information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selection uses and ordered dict\n",
    "Data_select_true = OrderedDict([])\n",
    "Data_select_reco = OrderedDict([(\"Passed analyzer selection\", lambda x: x['passed']==1),\n",
    "                                ('Reco vtx in fidVol', lambda row: CheckBorderTPC(row['vx'],row['vy'],row['vz'],fid_arr))\n",
    "                               ])\n",
    "                                                                                              \n",
    "\n",
    "# Features uses a list of functions\n",
    "Data_feature_list =[DaughterInfo,ContainedRatio,ShowerChargeProfile,CalcRecoE,CalcDedx,OpticalInfo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function: loadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(filelist,                  # List of input files\n",
    "             selection_true,            # Function dict that contains the true based selection, applied before saving the compact complete dataframw\n",
    "             selection_reco,            # Ordered dictionary with bool function that act on rows\n",
    "             featurelist,               # list of functions returning columns\n",
    "             maxf=2,                    # Maximum number of files to loop over\n",
    "             outputname='output'        # Name of the final picle file\n",
    "            ):\n",
    "    \n",
    "    chunks = []                                 # list of small dataframes with all info\n",
    "    chunks_nonpassed = []                       # list of small dataframes for failed event bookkeeping\n",
    "    entries = 0                                 # entries before selection\n",
    "    counter = np.zeros(len(selection_reco)+len(selection_true))      # counts number of events passing each stage\n",
    "    total_pot = 0                               # total POT of the sample\n",
    "    \n",
    "    nfiles=len(filelist)\n",
    "    if maxf<nfiles:\n",
    "        nfiles=maxf\n",
    "        \n",
    "    print ('Start to load entries from',nfiles,'files.\\n')\n",
    "    start_time = time.time()\n",
    "    \n",
    "    progress=0\n",
    "    for i_f,fname in enumerate(filelist[:nfiles]):\n",
    "        if(i_f % math.ceil(nfiles/10)==0 ):\n",
    "            print ('Progress:',progress,'%.')\n",
    "            progress+=10\n",
    "            \n",
    "        # Store the POT of the sample\n",
    "        total_pot+=read_root(fname,\"robertoana/pot\",columns='pot').sum()\n",
    "        \n",
    "        dftemp=read_root(fname,\"robertoana/pandoratree\")\n",
    "        entries+=len(dftemp.index)\n",
    "        \n",
    "        # Truth based selection\n",
    "        for index,(key, value) in enumerate(selection_true.items()):\n",
    "            dftemp = dftemp[dftemp.apply(value,axis=1)]\n",
    "            counter[index]+=len(dftemp.index)\n",
    "            \n",
    "        # Store some basic things about events that did not pass the selection! (but passed the truth selection)\n",
    "        dftemp_nonpassed = dftemp[dftemp['passed']==0][['nu_pdg','nu_E','true_vx_sce','true_vy_sce','true_vz_sce',\n",
    "                                                        'category','bnbweight']]\n",
    "        # This compact dataframe should also have some optical information.\n",
    "        dftemp_nonpassed = pd.concat([dftemp_nonpassed, dftemp[dftemp['passed']==0].apply(OpticalInfo,axis=1)], axis=1)\n",
    "        dftemp_nonpassed = pd.concat([dftemp_nonpassed, dftemp[dftemp['passed']==0].apply(FlashPrecut,axis=1)], axis=1)\n",
    "        chunks_nonpassed.append(dftemp_nonpassed)\n",
    "        \n",
    "        # Reco based selection\n",
    "        for index,(key, value) in enumerate(selection_reco.items()):\n",
    "            dftemp = dftemp[dftemp.apply(value,axis=1)]\n",
    "            counter[index+len(selection_true)]+=len(dftemp.index)\n",
    "            \n",
    "        #if no events passed, stop here\n",
    "        if(len(dftemp.index)==0):\n",
    "            continue\n",
    "        \n",
    "        # introduce the new flattened dataframe:\n",
    "        df_new = dftemp[flat_columns]\n",
    "        \n",
    "        # Reduce the dataframe size of the vector columns\n",
    "        for col in vec_columns:\n",
    "            df_new[col]=dftemp[col].apply(safely_reduce_dtype)\n",
    "        \n",
    "        # add new features to it\n",
    "        for value in featurelist:\n",
    "            df_new = pd.concat([df_new, dftemp.apply(value,axis=1)], axis=1)\n",
    "            \n",
    "        chunks.append(df_new)\n",
    "        \n",
    "       \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('\\nSummary:')\n",
    "    print (entries,'entries were loaded from',nfiles,'files, corresponding to',str(total_pot[0]),'POT.')\n",
    "    for key,counts in zip(list(selection_true.keys())+list(selection_reco.keys()),counter):\n",
    "        print(counts,'Passed \"',key,'\" stage of selection.')\n",
    "        \n",
    "    print('\\nLoading took ',sciNot(end_time-start_time),' seconds.')       \n",
    "    print('Concatenating output dataframes')\n",
    "    #Reduce the dataframe size or the non vector columns\n",
    "    df = pd.concat(chunks,ignore_index=True,copy=False) \n",
    "    df,_ = reduce_mem_usage(df)\n",
    "    df.to_pickle('../Input/'+outputname+'.pckl')\n",
    "    \n",
    "    #df_nonpassed = pd.concat(chunks_nonpassed,ignore_index=True,copy=False) \n",
    "    #df_nonpassed,_ = reduce_mem_usage(df_nonpassed)\n",
    "    #df_nonpassed.to_pickle('Input/'+outputname+'_nonpassed.pckl')\n",
    "    \n",
    "    print ('Final dataframe has',len(df.index),'entries.')\n",
    "    \n",
    "    end2_time = time.time()\n",
    "    print('Pickling took ',sciNot(end2_time-end_time),' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataframe and save to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to load entries from 2 files.\n",
      "\n",
      "Progress: 0 %.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wouter/anaconda3/envs/rootenv/lib/python3.4/site-packages/ipykernel/__main__.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/wouter/anaconda3/envs/rootenv/lib/python3.4/site-packages/ipykernel/__main__.py:143: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2147483648]\n",
      "[0]\n",
      "Progress: 10 %.\n",
      "[-2147483648]\n",
      "[0]\n",
      "\n",
      "Summary:\n",
      "48 entries were loaded from 2 files, corresponding to 0.0 POT.\n",
      "2.0 Passed \" Passed analyzer selection \" stage of selection.\n",
      "2.0 Passed \" Reco vtx in fidVol \" stage of selection.\n",
      "\n",
      "Loading took  2.4  seconds.\n",
      "Concatenating output dataframes\n",
      "Final dataframe has 2 entries.\n",
      "Pickling took  0.0  seconds.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loadData(filelist,          # List of input files\n",
    "             Intime_select_true,           # Function dict that contains the true based selection, applied before saving the compact complete dataframw\n",
    "             Intime_select_reco,           # Ordered dictionary with bool function that act on rows\n",
    "             Intime_feature_list,          # list of functions returning columns\n",
    "             maxf=2,                  # Maximum number of files to loop over\n",
    "             outputname='intime'           # Name of the final picle file\n",
    "            )\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample = pd.read_pickle('../Input/intime.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>subrun</th>\n",
       "      <th>run</th>\n",
       "      <th>nu_pdg</th>\n",
       "      <th>nu_E</th>\n",
       "      <th>true_vx_sce</th>\n",
       "      <th>true_vy_sce</th>\n",
       "      <th>true_vz_sce</th>\n",
       "      <th>distance</th>\n",
       "      <th>category</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "      <th>bnbweight</th>\n",
       "      <th>passed</th>\n",
       "      <th>shower_open_angle</th>\n",
       "      <th>shower_length</th>\n",
       "      <th>shower_start_x</th>\n",
       "      <th>shower_start_y</th>\n",
       "      <th>shower_start_z</th>\n",
       "      <th>shower_dir_x</th>\n",
       "      <th>shower_dir_y</th>\n",
       "      <th>shower_dir_z</th>\n",
       "      <th>shower_pca</th>\n",
       "      <th>track_start_x</th>\n",
       "      <th>track_start_y</th>\n",
       "      <th>track_start_z</th>\n",
       "      <th>track_end_x</th>\n",
       "      <th>track_end_y</th>\n",
       "      <th>track_end_z</th>\n",
       "      <th>track_dir_x</th>\n",
       "      <th>track_dir_y</th>\n",
       "      <th>track_dir_z</th>\n",
       "      <th>track_pca</th>\n",
       "      <th>predict_em</th>\n",
       "      <th>predict_mu</th>\n",
       "      <th>predict_cos</th>\n",
       "      <th>predict_pi</th>\n",
       "      <th>predict_p</th>\n",
       "      <th>nu_daughters_pdg</th>\n",
       "      <th>nu_daughters_E</th>\n",
       "      <th>nu_daughters_px</th>\n",
       "      <th>nu_daughters_py</th>\n",
       "      <th>nu_daughters_pz</th>\n",
       "      <th>nu_daughters_endx</th>\n",
       "      <th>nu_daughters_endy</th>\n",
       "      <th>nu_daughters_endz</th>\n",
       "      <th>true_shower_pdg</th>\n",
       "      <th>true_shower_x_sce</th>\n",
       "      <th>true_shower_y_sce</th>\n",
       "      <th>true_shower_z_sce</th>\n",
       "      <th>true_shower_depE</th>\n",
       "      <th>shower_daughter</th>\n",
       "      <th>track_daughter</th>\n",
       "      <th>shower_containment_q</th>\n",
       "      <th>shower_sp_profile</th>\n",
       "      <th>reconstructed_energy</th>\n",
       "      <th>shower_energy</th>\n",
       "      <th>shower_nhits</th>\n",
       "      <th>total_nhits</th>\n",
       "      <th>track_energy</th>\n",
       "      <th>track_nhits</th>\n",
       "      <th>shower_dedx</th>\n",
       "      <th>shower_dedx_avg</th>\n",
       "      <th>shower_dedx_hits</th>\n",
       "      <th>track_dedx</th>\n",
       "      <th>track_dedx_avg</th>\n",
       "      <th>track_dedx_hits</th>\n",
       "      <th>flash_PE</th>\n",
       "      <th>flash_time</th>\n",
       "      <th>matched_showers</th>\n",
       "      <th>matched_showers_energy</th>\n",
       "      <th>matched_tracks</th>\n",
       "      <th>matched_tracks_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1934194</td>\n",
       "      <td>3869</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0</td>\n",
       "      <td>226.058136</td>\n",
       "      <td>31.292021</td>\n",
       "      <td>207.289459</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.54785, 0.25171]</td>\n",
       "      <td>[10.172, 3.3008]</td>\n",
       "      <td>[222.38, 227.5]</td>\n",
       "      <td>[39.281, 31.656]</td>\n",
       "      <td>[159.25, 207.88]</td>\n",
       "      <td>[0.48877, 0.27002]</td>\n",
       "      <td>[-0.74805, 0.51025]</td>\n",
       "      <td>[-0.44897, 0.81641]</td>\n",
       "      <td>[0.89111, 0.81055]</td>\n",
       "      <td>[63.688]</td>\n",
       "      <td>[117.19]</td>\n",
       "      <td>[819.5]</td>\n",
       "      <td>[38.906]</td>\n",
       "      <td>[68.562]</td>\n",
       "      <td>[830.5]</td>\n",
       "      <td>[-0.41357]</td>\n",
       "      <td>[-0.89111]</td>\n",
       "      <td>[0.18579]</td>\n",
       "      <td>[0.99609]</td>\n",
       "      <td>[0.0070457]</td>\n",
       "      <td>[0.38501]</td>\n",
       "      <td>[0.49829]</td>\n",
       "      <td>[0.098022]</td>\n",
       "      <td>[0.011719]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>2.103284</td>\n",
       "      <td>0.095245</td>\n",
       "      <td>[0.0125984284375, 0.0135024714498]</td>\n",
       "      <td>[24.0, 17.0]</td>\n",
       "      <td>353</td>\n",
       "      <td>[0.0691439698895]</td>\n",
       "      <td>[23.0]</td>\n",
       "      <td>[0.884589348887, 2.18951229204]</td>\n",
       "      <td>[1.12600407995, 8.22550870248]</td>\n",
       "      <td>[3.0, 8.0]</td>\n",
       "      <td>[1.38769474639]</td>\n",
       "      <td>[8.14818542774]</td>\n",
       "      <td>[7.0]</td>\n",
       "      <td>956.010071</td>\n",
       "      <td>4.501875</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1934194</td>\n",
       "      <td>3869</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>6</td>\n",
       "      <td>226.058136</td>\n",
       "      <td>31.292021</td>\n",
       "      <td>207.289459</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.54785, 0.25171]</td>\n",
       "      <td>[10.172, 3.3008]</td>\n",
       "      <td>[222.38, 227.5]</td>\n",
       "      <td>[39.281, 31.656]</td>\n",
       "      <td>[159.25, 207.88]</td>\n",
       "      <td>[0.48877, 0.27002]</td>\n",
       "      <td>[-0.74805, 0.51025]</td>\n",
       "      <td>[-0.44897, 0.81641]</td>\n",
       "      <td>[0.89111, 0.81055]</td>\n",
       "      <td>[63.688]</td>\n",
       "      <td>[117.19]</td>\n",
       "      <td>[819.5]</td>\n",
       "      <td>[38.906]</td>\n",
       "      <td>[68.562]</td>\n",
       "      <td>[830.5]</td>\n",
       "      <td>[-0.41357]</td>\n",
       "      <td>[-0.89111]</td>\n",
       "      <td>[0.18579]</td>\n",
       "      <td>[0.99609]</td>\n",
       "      <td>[0.0070457]</td>\n",
       "      <td>[0.38501]</td>\n",
       "      <td>[0.49829]</td>\n",
       "      <td>[0.098022]</td>\n",
       "      <td>[0.011719]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>2.103284</td>\n",
       "      <td>0.095245</td>\n",
       "      <td>[0.0125984284375, 0.0135024714498]</td>\n",
       "      <td>[24.0, 17.0]</td>\n",
       "      <td>353</td>\n",
       "      <td>[0.0691439698895]</td>\n",
       "      <td>[23.0]</td>\n",
       "      <td>[0.884589348887, 2.18951229204]</td>\n",
       "      <td>[1.12600407995, 8.22550870248]</td>\n",
       "      <td>[3.0, 8.0]</td>\n",
       "      <td>[1.38769474639]</td>\n",
       "      <td>[8.14818542774]</td>\n",
       "      <td>[7.0]</td>\n",
       "      <td>956.010071</td>\n",
       "      <td>4.501875</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     event  subrun  run  nu_pdg  nu_E  true_vx_sce  true_vy_sce  true_vz_sce  \\\n",
       "0  1934194    3869    2       0  -inf         -inf         -inf         -inf   \n",
       "1  1934194    3869    2       0  -inf         -inf         -inf         -inf   \n",
       "\n",
       "   distance  category          vx         vy          vz   bnbweight  passed  \\\n",
       "0       inf         0  226.058136  31.292021  207.289459 -2147483648       1   \n",
       "1      -inf         6  226.058136  31.292021  207.289459 -2147483648       1   \n",
       "\n",
       "    shower_open_angle     shower_length   shower_start_x    shower_start_y  \\\n",
       "0  [0.54785, 0.25171]  [10.172, 3.3008]  [222.38, 227.5]  [39.281, 31.656]   \n",
       "1  [0.54785, 0.25171]  [10.172, 3.3008]  [222.38, 227.5]  [39.281, 31.656]   \n",
       "\n",
       "     shower_start_z        shower_dir_x         shower_dir_y  \\\n",
       "0  [159.25, 207.88]  [0.48877, 0.27002]  [-0.74805, 0.51025]   \n",
       "1  [159.25, 207.88]  [0.48877, 0.27002]  [-0.74805, 0.51025]   \n",
       "\n",
       "          shower_dir_z          shower_pca track_start_x track_start_y  \\\n",
       "0  [-0.44897, 0.81641]  [0.89111, 0.81055]      [63.688]      [117.19]   \n",
       "1  [-0.44897, 0.81641]  [0.89111, 0.81055]      [63.688]      [117.19]   \n",
       "\n",
       "  track_start_z track_end_x track_end_y track_end_z track_dir_x track_dir_y  \\\n",
       "0       [819.5]    [38.906]    [68.562]     [830.5]  [-0.41357]  [-0.89111]   \n",
       "1       [819.5]    [38.906]    [68.562]     [830.5]  [-0.41357]  [-0.89111]   \n",
       "\n",
       "  track_dir_z  track_pca   predict_em predict_mu predict_cos  predict_pi  \\\n",
       "0   [0.18579]  [0.99609]  [0.0070457]  [0.38501]   [0.49829]  [0.098022]   \n",
       "1   [0.18579]  [0.99609]  [0.0070457]  [0.38501]   [0.49829]  [0.098022]   \n",
       "\n",
       "    predict_p nu_daughters_pdg nu_daughters_E nu_daughters_px nu_daughters_py  \\\n",
       "0  [0.011719]               []             []              []              []   \n",
       "1  [0.011719]               []             []              []              []   \n",
       "\n",
       "  nu_daughters_pz nu_daughters_endx nu_daughters_endy nu_daughters_endz  \\\n",
       "0              []                []                []                []   \n",
       "1              []                []                []                []   \n",
       "\n",
       "  true_shower_pdg true_shower_x_sce true_shower_y_sce true_shower_z_sce  \\\n",
       "0              []                []                []                []   \n",
       "1              []                []                []                []   \n",
       "\n",
       "  true_shower_depE shower_daughter track_daughter  shower_containment_q  \\\n",
       "0               []          [0, 0]            [0]              0.999991   \n",
       "1               []          [0, 0]            [0]              0.999991   \n",
       "\n",
       "   shower_sp_profile  reconstructed_energy  \\\n",
       "0           2.103284              0.095245   \n",
       "1           2.103284              0.095245   \n",
       "\n",
       "                        shower_energy  shower_nhits  total_nhits  \\\n",
       "0  [0.0125984284375, 0.0135024714498]  [24.0, 17.0]          353   \n",
       "1  [0.0125984284375, 0.0135024714498]  [24.0, 17.0]          353   \n",
       "\n",
       "        track_energy track_nhits                      shower_dedx  \\\n",
       "0  [0.0691439698895]      [23.0]  [0.884589348887, 2.18951229204]   \n",
       "1  [0.0691439698895]      [23.0]  [0.884589348887, 2.18951229204]   \n",
       "\n",
       "                  shower_dedx_avg shower_dedx_hits       track_dedx  \\\n",
       "0  [1.12600407995, 8.22550870248]       [3.0, 8.0]  [1.38769474639]   \n",
       "1  [1.12600407995, 8.22550870248]       [3.0, 8.0]  [1.38769474639]   \n",
       "\n",
       "    track_dedx_avg track_dedx_hits    flash_PE  flash_time matched_showers  \\\n",
       "0  [8.14818542774]           [7.0]  956.010071    4.501875          [0, 0]   \n",
       "1  [8.14818542774]           [7.0]  956.010071    4.501875          [0, 0]   \n",
       "\n",
       "  matched_showers_energy matched_tracks matched_tracks_energy  \n",
       "0             [0.0, 0.0]            [0]                 [0.0]  \n",
       "1             [0.0, 0.0]            [0]                 [0.0]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:rootenv]",
   "language": "python",
   "name": "conda-env-rootenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
