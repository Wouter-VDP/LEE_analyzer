{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEE Analyzer notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes in the output directory of the jobs and convert it into a more flat pandas dataframe. \n",
    "Data from the root files will be partially processed to fields that are convenient to plot.\n",
    "The resulting dataframe will be pickled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from root_pandas import read_root\n",
    "from collections import OrderedDict\n",
    "\n",
    "from helpfunction import safely_reduce_dtype,reduce_mem_usage,sciNot,CheckBorderTPC,CheckBorderFixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999\n",
    "gr      = 1.618\n",
    "nan     = -2147483648\n",
    "min_root_size = 20000 # Skip root files smaller than x bytes\n",
    "\n",
    "mass_p= 0.93827 #GeV\n",
    "mass_e= 0.00511 #GeV\n",
    "\n",
    "# LAr EM showers\n",
    "R_moliere =  9.5 # cm\n",
    "X_o       = 13.9 # cm\n",
    "E_c       = 0.035# GeV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Which plane do we want to use:\n",
    "plane = 2 # collection plane only\n",
    "\n",
    "# Fiducial volume borders in x,y,z:\n",
    "fid_arr= [[10,10],[20,20],[10,50]]\n",
    "# Fiducial volume for the end points of tracks\n",
    "fid_min = 10\n",
    "# Percentage cut for shower containment\n",
    "sh_cont_percent = .75\n",
    "\n",
    "# Minimum reconstructable energies:\n",
    "min_e = 0.02+mass_e # 20MeV\n",
    "min_p = 0.04+mass_p # 40MeV\n",
    "\n",
    "# Flat columns we want to copy from the original dataframe:\n",
    "flat_columns = ['nu_pdg','nu_E','true_vx_sce','true_vy_sce','true_vz_sce',\n",
    "                'distance','category','vx','vy','vz','bnbweight','passed']\n",
    "\n",
    "vec_columns = ['shower_open_angle','shower_length','shower_start_x','shower_start_y','shower_start_z',\n",
    "              'shower_dir_x','shower_dir_y','shower_dir_z','shower_pca',\n",
    "\n",
    "              'track_start_x','track_start_y','track_start_z','track_end_x','track_end_y','track_end_z',\n",
    "              'track_dir_x','track_dir_y','track_dir_z','track_pca',\n",
    "              'predict_em','predict_mu','predict_cos','predict_pi','predict_p',\n",
    "\n",
    "              'nu_daughters_pdg','nu_daughters_E','nu_daughters_px','nu_daughters_py','nu_daughters_pz',\n",
    "              'nu_daughters_endx','nu_daughters_endy','nu_daughters_endz',\n",
    "              'true_shower_pdg','true_shower_x_sce','true_shower_y_sce','true_shower_z_sce','true_shower_depE'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/wouter/Templates/nue/3396777_221/PandoraLEEAnalyzer.root was corrupt. Size: 0.434 kb, skipping to next file.\n",
      "253 valid ROOT files collected.\n"
     ]
    }
   ],
   "source": [
    "# Input directory\n",
    "# Can be on gpvms, example: '/run/user/1000/gvfs/sftp:host=uboonegpvm02.fnal.gov,user=wvdp/uboone/data/users/wvdp/v06_26_01_10/data_bnb_a_1e0p/*/*.root'\n",
    "# Local will be faster, avoid using pnfs scratch\n",
    "\n",
    "inputlist = glob.glob('/home/wouter/Templates/nue/*/*.root')\n",
    "filelist  = []\n",
    "for fname in inputlist:\n",
    "    if (os.stat(fname).st_size)<min_root_size:\n",
    "            print('File',fname,'was corrupt. Size:',os.stat(fname).st_size/1000, 'kb, skipping to next file.')\n",
    "    else:\n",
    "        filelist.append(fname)\n",
    "print(len(filelist),'valid ROOT files collected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Signal Definition 1e0p \n",
    "def true_thresholds_1e0p(row):\n",
    "    if CheckBorderTPC(row['true_vx_sce'],row['true_vy_sce'],row['true_vz_sce'],fid_arr):\n",
    "        passed_e=False\n",
    "        for pdg,E in zip(row[\"nu_daughters_pdg\"],row[\"nu_daughters_E\"]):\n",
    "            if pdg==11 and E>min_e:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verifies if the event passed the flash precuts.\n",
    "def FlashPrecut(row):\n",
    "    flash_ok = False\n",
    "    t_start = 3.2\n",
    "    t_end   = t_start+1.6\n",
    "    min_PE  = 50\n",
    "\n",
    "    for time,PE in zip(row['flash_time'],row['flash_PE']):\n",
    "        if time>t_start and time<t_end and PE>min_PE:\n",
    "            flash_ok = True\n",
    "    return pd.Series({\"flash_precut\": flash_ok}) \n",
    "\n",
    "\n",
    "\n",
    "# Reconstructed energy using collection plane\n",
    "def CalcRecoE(row):\n",
    "    reco_energy = 0\n",
    "    total_nhits = 0 # sum over all the planes\n",
    "    shower_nhits = np.zeros(row['n_showers']) \n",
    "    shower_energy = np.zeros(row['n_showers'])\n",
    "    track_nhits = np.zeros(row['n_tracks'])\n",
    "    track_energy = np.zeros(row['n_tracks'])\n",
    "    \n",
    "    for tr, tr_E, nhits in zip(range(row['n_tracks']),row['track_energy_hits'],row[\"track_nhits\"]):\n",
    "        reco_energy+=tr_E[plane]\n",
    "        track_nhits[tr] = int(nhits[plane])\n",
    "        track_energy[tr] = tr_E[plane]\n",
    "        total_nhits+=int(sum(nhits))\n",
    "        \n",
    "    for sh, sh_E, nhits in zip(range(row['n_showers']),row['shower_energy'],row[\"shower_nhits\"]):\n",
    "        reco_energy+=sh_E[plane]\n",
    "        shower_nhits[sh] = int(nhits[plane])\n",
    "        shower_energy[sh] = sh_E[plane]\n",
    "        total_nhits+=int(sum(nhits))\n",
    "        \n",
    "    return pd.Series({\"reconstructed_energy\": reco_energy, \"total_nhits\": total_nhits,\n",
    "                      \"shower_nhits\": shower_nhits, \"shower_energy\": shower_energy,\n",
    "                      \"track_nhits\": track_nhits, \"track_energy\": track_energy})\n",
    "\n",
    "\n",
    "\n",
    "# Add info about the pandora particle hierarchy\n",
    "def DaughterInfo(row):\n",
    "    nu_shower_ids, nu_track_ids                = row['nu_shower_ids'],row['nu_track_ids']\n",
    "    nu_shower_daughters, nu_track_daughters    = list(row['nu_shower_daughters']),list(row['nu_track_daughters'])\n",
    "\n",
    "    showerdaughter = []\n",
    "    for sh in nu_shower_daughters:\n",
    "        if len(sh)==0:\n",
    "            showerdaughter.append(0)\n",
    "        elif len(sh)==1:\n",
    "            if sh[0] in nu_shower_ids:\n",
    "                showerdaughter.append(1)\n",
    "            elif sh[0] in nu_track_ids:\n",
    "                showerdaughter.append(2)\n",
    "        else:\n",
    "            showerdaughter.append(3)\n",
    "            \n",
    "    trackdaughter = []\n",
    "    for tr in nu_track_daughters:\n",
    "        if len(tr)==0:\n",
    "            trackdaughter.append(0)\n",
    "        elif len(tr)==1:\n",
    "            if tr[0] in nu_shower_ids:\n",
    "                trackdaughter.append(1)\n",
    "            elif tr[0] in nu_track_ids:\n",
    "                trackdaughter.append(2)\n",
    "        else:\n",
    "            trackdaughter.append(3)\n",
    "    return pd.Series({\"shower_daughter\": showerdaughter, \"track_daughter\": trackdaughter})     \n",
    "\n",
    "\n",
    "\n",
    "# Calculates the true end point for electron showers, for 95% of energy\n",
    "def showerTrueEnd(row):\n",
    "    if 11 not in row['nu_daughters_pdg']:\n",
    "        return pd.Series({\"true_shower_endx\": -999.0, \"true_shower_endy\": -999.0, \"true_shower_endz\": -999.0,\n",
    "                      \"true_shower_tmax_x\": -999.0, \"true_shower_tmax_y\": -999.0, \"true_shower_tmax_z\": -999.0})\n",
    "    i_daughter = np.nonzero(row['nu_daughters_pdg']==11)\n",
    "    if len(i_daughter[0])>1:\n",
    "        print('More than 1 true electron daughter')\n",
    "    i_daughter = i_daughter[0][0]\n",
    "    \n",
    "    E_ratio = (row['nu_daughters_E'][i_daughter])/E_c\n",
    "    t_max = np.log(E_ratio)-1.0\n",
    "    length = (t_max+0.08*18+9.6)*X_o\n",
    "    #print('E_ratio',E_ratio,'E',row['nu_daughters_E'][i_daughter],' t_max',t_max,'length',length)\n",
    "    direction = np.array([row['nu_daughters_px'][i_daughter],row['nu_daughters_py'][i_daughter],row['nu_daughters_pz'][i_daughter]])\n",
    "    true_shower_start = np.array([row['nu_daughters_vx'][i_daughter],row['nu_daughters_vy'][i_daughter],row['nu_daughters_vz'][i_daughter]])\n",
    "    true_shower_end = true_shower_start+length*direction/np.linalg.norm(direction)\n",
    "    true_shower_tmax = true_shower_start+(t_max*X_o)*direction/np.linalg.norm(direction)\n",
    "    \n",
    "    return pd.Series({\"true_shower_endx\": true_shower_end[0], \"true_shower_endy\": true_shower_end[1], \"true_shower_endz\": true_shower_end[2],\n",
    "                      \"true_shower_tmax_x\": true_shower_tmax[0], \"true_shower_tmax_y\": true_shower_tmax[1], \"true_shower_tmax_z\": true_shower_tmax[2]})\n",
    "\n",
    "\n",
    "\n",
    "# Calculates the percentage of sps inside the fiducial volume and the percentage of deposited collection plane charge\n",
    "def ContainedRatio(row):\n",
    "    d=0.01\n",
    "    n=0.0\n",
    "    \n",
    "    for x,y,z,q in zip(row['shower_sp_x'],row['shower_sp_y'],row['shower_sp_z'],row['shower_sp_int']):\n",
    "        d+=q\n",
    "        if CheckBorderTPC(x,y,z,fid_arr):\n",
    "            n+=q\n",
    "\n",
    "    return pd.Series({\"shower_containment_q\": n/d}) \n",
    "\n",
    "\n",
    "\n",
    "def CC_daughter_E(row):\n",
    "    CC_daughter_i = np.nonzero(np.in1d(row['nu_daughters_pdg'], [11,-11,13,-13]))[0]\n",
    "    CC_daughter_E = -1\n",
    "    if len(CC_daughter_i)>0:\n",
    "        if len(CC_daughter_i)>2:\n",
    "            'Multiple electron/muon daughters found!'\n",
    "        else:      \n",
    "            CC_daughter_E = row['nu_daughters_E'][CC_daughter_i[0]]\n",
    "    return pd.Series({\"CC_daughter_E\": CC_daughter_E})  \n",
    "\n",
    "\n",
    "\n",
    "# Returns the ratio of collection charge of the first part and the second part of the summed shower.\n",
    "def ShowerChargeProfile(row):\n",
    "    x,y,z = row['vx'],row['vy'],row['vz']\n",
    "    sps_x_arr,sps_y_arr,sps_z_arr,sps_int_arr = row['shower_sp_x'],row['shower_sp_y'],row['shower_sp_z'],row['shower_sp_int']\n",
    "    \n",
    "    center= np.array([0.0,0.0,0.0])\n",
    "    total_Q = 0.0\n",
    "    for sps_x,sps_y,sps_z,sps_int in zip(sps_x_arr,sps_y_arr,sps_z_arr,sps_int_arr):\n",
    "        center+=np.array([sps_x,sps_y,sps_z])*sps_int\n",
    "        total_Q+=sps_int\n",
    "    center/=total_Q\n",
    "    norm = (center-np.array([x,y,z])) / np.linalg.norm(center-np.array([x,y,z]))\n",
    "    \n",
    "    distance = []\n",
    "    for sps_x,sps_y,sps_z in zip(sps_x_arr,sps_y_arr,sps_z_arr):\n",
    "        distance.append( np.dot([sps_x-x,sps_y-y,sps_z-z],norm) )\n",
    "        \n",
    "    y,x = np.histogram( distance, weights = sps_int_arr )\n",
    "    l = len(y)/2\n",
    "    return pd.Series({\"shower_sp_profile\": np.mean(y[:l])/np.mean(y[-l:])})  \n",
    "\n",
    "\n",
    "# Returns the dedx and the number of hits it had to compute this.\n",
    "def CalcDedx(row):\n",
    "    shower_dedx_hits = np.zeros(row['n_showers']) \n",
    "    shower_dedx      = np.zeros(row['n_showers'])\n",
    "    shower_dedx_sum  = np.zeros(row['n_showers']) \n",
    "    \n",
    "    track_dedx_hits  = np.zeros(row['n_tracks'])\n",
    "    track_dedx       = np.zeros(row['n_tracks'])\n",
    "    track_dedx_sum   = np.zeros(row['n_tracks'])\n",
    "    \n",
    "    \n",
    "    for tr, tr_E, nhits in zip(range(row['n_tracks']),row['track_dEdx'],row[\"track_dEdx_hits\"]):\n",
    "        track_dedx_hits[tr] = len(nhits)\n",
    "        track_dedx_sum[tr] += sum(nhits)\n",
    "        track_dedx[tr]      = tr_E[plane]\n",
    "        \n",
    "    for sh, sh_E, nhits in zip(range(row['n_showers']),row['shower_dEdx'],row[\"shower_dEdx_hits\"]):\n",
    "        shower_dedx_hits[sh] = len(nhits)\n",
    "        shower_dedx_sum[sh] += sum(nhits)\n",
    "        shower_dedx[sh]      = sh_E[plane]\n",
    "        \n",
    "    shower_dedx_sum/=row['n_showers']\n",
    "    track_dedx_sum/=row['n_tracks']\n",
    "    \n",
    "    return pd.Series({\"shower_dedx_hits\": shower_dedx_hits, \"shower_dedx\": shower_dedx, \"shower_dedx_avg\": shower_dedx_sum,\n",
    "                      \"track_dedx_hits\": track_dedx_hits, \"track_dedx\": track_dedx, \"track_dedx_avg\": track_dedx_sum})\n",
    "\n",
    "def OpticalInfo(row):\n",
    "    flash_PE=0\n",
    "    flash_time=0\n",
    "    if np.any(row['flash_passed']!=-1):\n",
    "        flash_PE = row['flash_PE'][np.max(row['flash_passed'])]\n",
    "        flash_time = row['flash_time'][np.max(row['flash_passed'])]\n",
    "    return pd.Series({\"flash_time\": flash_time, \"flash_PE\": flash_PE})\n",
    "\n",
    "def MatchedCleanup(row):\n",
    "    matched_tracks= row['matched_tracks']\n",
    "    matched_tracks[row['matched_tracks']==-2147483648] = 0\n",
    "    \n",
    "    matched_tracks_energy= row['matched_tracks_energy']\n",
    "    matched_tracks_energy[matched_tracks_energy<-1] = 0\n",
    "    \n",
    "    matched_showers= row['matched_showers']\n",
    "    matched_showers[row['matched_showers']==-2147483648] = 0\n",
    "    \n",
    "    matched_showers_energy= row['matched_showers_energy']\n",
    "    matched_showers_energy[matched_showers_energy<-1] = 0\n",
    "    \n",
    "    return pd.Series({\"matched_tracks\": matched_tracks, \"matched_tracks_energy\": matched_tracks_energy,\n",
    "                      \"matched_showers\": matched_showers, \"matched_showers_energy\": matched_showers_energy})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection & Features dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BNB $\\nu$ + cosmics \n",
    "\n",
    "\n",
    "selection: We want to keep only the passed events but no further cuts on truth information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selection uses and ordered dict\n",
    "Nu_select_true = OrderedDict([(\"Passed analyzer selection\", lambda x: x['passed']==1)])\n",
    "Nu_select_reco = OrderedDict([])\n",
    "\n",
    "# Features uses a list of functions\n",
    "Nu_feature_list =[DaughterInfo, ContainedRatio, ShowerChargeProfile, CalcRecoE, CalcDedx, OpticalInfo,\n",
    "                 CC_daughter_E, showerTrueEnd, MatchedCleanup] # The last row used true info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BNB $\\nu_e$ intrinsic + cosmics \n",
    "\n",
    "\n",
    "selection: We want to do an efficiency plot, therefore we will need to have the signal definition selection. Non passed events need also to be filtered on that requirement before they are saved. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selection uses and ordered dict\n",
    "Nue_select_true = OrderedDict([('Signal Definition 1e0p',true_thresholds_1e0p)])\n",
    "Nue_select_reco = OrderedDict([(\"Passed analyzer selection\", lambda x: x['passed']==1)])\n",
    "\n",
    "# Features uses a list of functions\n",
    "Nue_feature_list =[DaughterInfo, ContainedRatio, ShowerChargeProfile, CalcRecoE, CalcDedx, OpticalInfo,\n",
    "                 CC_daughter_E, showerTrueEnd, MatchedCleanup] # The last row used true info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BNB ext or BNB data samples\n",
    "\n",
    "\n",
    "selection: we only want to keep passed events \n",
    "\n",
    "\n",
    "We need to be carefull not adding features that depend on truth information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selection uses and ordered dict\n",
    "Data_select_true = OrderedDict([(\"Passed analyzer selection\", lambda x: x['passed']==1)])\n",
    "Data_select_reco = OrderedDict([])\n",
    "\n",
    "# Features uses a list of functions\n",
    "Data_feature_list =[DaughterInfo,FlashPrecut,ContainedRatio,ShowerChargeProfile,CalcRecoE,CalcDedx,OpticalInfo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Function: loadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(filelist,                  # List of input files\n",
    "             selection_true,            # Function dict that contains the true based selection, applied before saving the compact complete dataframw\n",
    "             selection_reco,            # Ordered dictionary with bool function that act on rows\n",
    "             featurelist,               # list of functions returning columns\n",
    "             maxf=2,                    # Maximum number of files to loop over\n",
    "             outputname='output'        # Name of the final picle file\n",
    "            ):\n",
    "    \n",
    "    chunks = []                                 # list of small dataframes with all info\n",
    "    chunks_nonpassed = []                       # list of small dataframes for failed event bookkeeping\n",
    "    entries = 0                                 # entries before selection\n",
    "    counter = np.zeros(len(selection_reco)+len(selection_true))      # counts number of events passing each stage\n",
    "    total_pot = 0                               # total POT of the sample\n",
    "    \n",
    "    nfiles=len(filelist)\n",
    "    if maxf<nfiles:\n",
    "        nfiles=maxf\n",
    "        \n",
    "    print ('Start to load entries from',nfiles,'files.\\n')\n",
    "    start_time = time.time()\n",
    "    \n",
    "    progress=0\n",
    "    for i_f,fname in enumerate(filelist[:nfiles]):\n",
    "        if(i_f % math.ceil(nfiles/10)==0 ):\n",
    "            print ('Progress:',progress,'%.')\n",
    "            progress+=10\n",
    "            \n",
    "        # Store the POT of the sample\n",
    "        total_pot+=read_root(fname,\"robertoana/pot\",columns='pot').sum()\n",
    "        \n",
    "        dftemp=read_root(fname,\"robertoana/pandoratree\")\n",
    "        entries+=len(dftemp.index)\n",
    "        \n",
    "        # Truth based selection\n",
    "        for index,(key, value) in enumerate(selection_true.items()):\n",
    "            dftemp = dftemp[dftemp.apply(value,axis=1)]\n",
    "            counter[index]+=len(dftemp.index)\n",
    "            \n",
    "        # Store some basic things about events that did not pass the selection! (but passed the truth selection)\n",
    "        dftemp_nonpassed = dftemp[dftemp['passed']==0][['nu_pdg','nu_E','true_vx_sce','true_vy_sce','true_vz_sce',\n",
    "                                                        'category','bnbweight']]\n",
    "        # This compact dataframe should also have some optical information.\n",
    "        dftemp_nonpassed = pd.concat([dftemp_nonpassed, dftemp[dftemp['passed']==0].apply(OpticalInfo,axis=1)], axis=1)\n",
    "        \n",
    "        # Reco based selection\n",
    "        for index,(key, value) in enumerate(selection_reco.items()):\n",
    "            dftemp = dftemp[dftemp.apply(value,axis=1)]\n",
    "            counter[index+len(selection_reco)]+=len(dftemp.index)\n",
    "        \n",
    "        # introduce the new flattened dataframe:\n",
    "        df_new = dftemp[flat_columns]\n",
    "        #df_new['shower_dEdx_hits'] = dftemp['shower_dEdx_hits']\n",
    "        #df_new['shower_dEdx'] = dftemp['shower_dEdx']\n",
    "        \n",
    "        # Reduce the dataframe size of the vector columns\n",
    "        for col in vec_columns:\n",
    "            df_new[col]=dftemp[col].apply(safely_reduce_dtype)\n",
    "        \n",
    "        # add new features to it\n",
    "        for value in featurelist:\n",
    "            df_new = pd.concat([df_new, dftemp.apply(value,axis=1)], axis=1)\n",
    "            \n",
    "        chunks.append(df_new)\n",
    "        chunks_nonpassed.append(dftemp_nonpassed)\n",
    "       \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('\\nSummary:')\n",
    "    print (entries,'entries were loaded from',nfiles,'files, corresponding to',str(total_pot[0]),'POT.')\n",
    "    for key,counts in zip(list(selection_true.keys())+list(selection_reco.keys()),counter):\n",
    "        print(counts,'Passed \"',key,'\" stage of selection.')\n",
    "        \n",
    "    print('\\nLoading took ',sciNot(end_time-start_time),' seconds.')       \n",
    "    print('Concatenating output dataframes')\n",
    "    df = pd.concat(chunks,ignore_index=True,copy=False) \n",
    "    df_nonpassed = pd.concat(chunks_nonpassed,ignore_index=True,copy=False) \n",
    "    print ('Final dataframe has',len(df.index),'entries.')\n",
    "    \n",
    "    #Reduce the dataframe size or the non vector columns\n",
    "    df,_ = reduce_mem_usage(df)\n",
    "    df_nonpassed,_ = reduce_mem_usage(df_nonpassed)\n",
    "    \n",
    "    df.to_pickle('Input/'+outputname+'.pckl')\n",
    "    df_nonpassed.to_pickle('Input/'+outputname+'_nonpassed.pckl')\n",
    "    end2_time = time.time()\n",
    "    print('Pickling took ',sciNot(end2_time-end_time),' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataframe and save to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to load entries from 253 files.\n",
      "\n",
      "Progress: 0 %.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wouter/anaconda3/envs/rootenv/lib/python3.4/site-packages/ipykernel/__main__.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/wouter/anaconda3/envs/rootenv/lib/python3.4/site-packages/ipykernel/__main__.py:143: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/wouter/anaconda3/envs/rootenv/lib/python3.4/site-packages/ipykernel/__main__.py:134: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/wouter/anaconda3/envs/rootenv/lib/python3.4/site-packages/ipykernel/__main__.py:143: RuntimeWarning: invalid value encountered in float_scalars\n",
      "/home/wouter/anaconda3/envs/rootenv/lib/python3.4/site-packages/ipykernel/__main__.py:143: RuntimeWarning: divide by zero encountered in float_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 1 true electron daughter\n"
     ]
    }
   ],
   "source": [
    "loadData(filelist,          # List of input files\n",
    "             Nue_select_true,           # Function dict that contains the true based selection, applied before saving the compact complete dataframw\n",
    "             Nue_select_reco,           # Ordered dictionary with bool function that act on rows\n",
    "             Nue_feature_list,          # list of functions returning columns\n",
    "             maxf=300,                  # Maximum number of files to loop over\n",
    "             outputname='nue'           # Name of the final picle file\n",
    "            )\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:rootenv]",
   "language": "python",
   "name": "conda-env-rootenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
