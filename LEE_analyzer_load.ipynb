{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEE Analyzer notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from root_numpy import list_branches\n",
    "from root_pandas import read_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999\n",
    "gr      = 1.618\n",
    "nan     = -2147483648\n",
    "\n",
    "mass_p= 0.93827 #GeV\n",
    "mass_e= 0.00511 #GeV\n",
    "\n",
    "# LAr EM showers\n",
    "R_moliere =  9.5 # cm\n",
    "X_o       = 13.9 # cm\n",
    "E_c       = 0.035# GeV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionary translating the category field in the root tree\n",
    "categories={1: 'Cosmic',\n",
    "            2: 'e CC',\n",
    "            3: 'mu CC',\n",
    "            4: 'NC',\n",
    "            5: 'Dirt',\n",
    "            6: 'Data',\n",
    "            7: 'Mixed',\n",
    "            0: 'Other'}\n",
    "\n",
    "# Fiducial volume borders in x,y,z:\n",
    "fid_arr= [[10,10],[20,20],[10,50]]\n",
    "# Fiducial volume for the end points of tracks\n",
    "fid_min = 10\n",
    "sh_cont_percent = .75\n",
    "\n",
    "# Minimum reconstructable energies:\n",
    "min_e = 0.02+mass_e # 20MeV\n",
    "min_p = 0.04+mass_p # 40MeV\n",
    "\n",
    "# list ROOT files\n",
    "#filelist = glob.glob('/home/wouter/Public/*/*.root')\n",
    "filelist = glob.glob('/home/wouter/Templates/nue/*/*.root')\n",
    "\n",
    "# List of fields in the ROOT tree you want to include\n",
    "columns = ['n_tracks','n_showers','vx','vy','vz','category','distance',\n",
    "           'nu_pdg','interaction_type',\n",
    "           'true_vx_sce','true_vy_sce','true_vz_sce','nu_E','true_shower_depE',\n",
    "           'true_shower_x_sce','true_shower_y_sce','true_shower_z_sce','true_shower_pdg',\n",
    "           'nu_daughters_pdg','nu_daughters_E',\n",
    "           'nu_daughters_endx','nu_daughters_endy',\"nu_daughters_endz\",\n",
    "           'nu_daughters_px','nu_daughters_py','nu_daughters_pz',\n",
    "           'nu_track_ids','nu_shower_ids','nu_shower_daughters','nu_track_daughters',\n",
    "           'flash_PE','flash_time',\n",
    "           'shower_dir_x','shower_dir_y','shower_dir_z',\n",
    "           \"shower_start_x\",\"shower_start_y\",\"shower_start_z\",\n",
    "           'shower_open_angle','shower_length',\n",
    "           \"shower_energy\",\"track_energy_dedx\",\"track_energy_hits\",\n",
    "           \"track_dir_x\",\"track_dir_y\",\"track_dir_z\",\n",
    "           \"track_start_x\",\"track_start_y\",\"track_start_z\",\n",
    "           'track_end_x','track_end_y','track_end_z',\n",
    "           'predict_p','predict_mu','predict_pi','predict_em','predict_cos',\n",
    "           'shower_pca','track_pca','track_nhits','shower_nhits',\n",
    "           'matched_showers','matched_tracks','matched_tracks_energy','matched_showers_energy',\n",
    "           'shower_dEdx_hits','track_dEdx_hits'\n",
    "          ]\n",
    "\n",
    "columns_remove_extra = ['n_tracks','n_showers','vx','vy','vz','interaction_type',\n",
    "           'true_shower_x_sce','true_shower_y_sce','true_shower_z_sce',\n",
    "           'nu_daughters_endx','nu_daughters_endy',\"nu_daughters_endz\",\n",
    "           'nu_daughters_px','nu_daughters_py','nu_daughters_pz',\n",
    "           'nu_track_ids','nu_shower_ids','nu_shower_daughters','nu_track_daughters',\n",
    "           'flash_PE','flash_time',\n",
    "           'shower_open_angle',\n",
    "           \"track_energy_dedx\",\"track_energy_hits\",\n",
    "           'predict_mu','predict_pi','predict_em','predict_cos',\n",
    "           'shower_pca','track_pca',\n",
    "           'shower_dEdx_hits','track_dEdx_hits'\n",
    "          ]\n",
    "\n",
    "#print(filelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def showerChargeProfile(row):\n",
    "    x,y,z = row['vx'],row['vy'],row['vz']\n",
    "    sps_x_arr,sps_y_arr,sps_z_arr,sps_int_arr = row['shower_sp_x'],row['shower_sp_y'],row['shower_sp_z'],row['shower_sp_int']\n",
    "    \n",
    "    center= np.array([0.0,0.0,0.0])\n",
    "    total_Q = 0.0\n",
    "    for sps_x,sps_y,sps_z,sps_int in zip(sps_x_arr,sps_y_arr,sps_z_arr,sps_int_arr):\n",
    "        center+=np.array([sps_x,sps_y,sps_z])*sps_int\n",
    "        total_Q+=sps_int\n",
    "    center/=total_Q\n",
    "    norm = (center-np.array([x,y,z])) / np.linalg.norm(center-np.array([x,y,z]))\n",
    "    \n",
    "    distance = []\n",
    "    for sps_x,sps_y,sps_z in zip(sps_x_arr,sps_y_arr,sps_z_arr):\n",
    "        distance.append( np.dot([sps_x-x,sps_y-y,sps_z-z],norm) )\n",
    "        \n",
    "    y,x = np.histogram( distance, weights = sps_int_arr )\n",
    "    return np.mean(y[:5])/np.mean(y[-5:])>1\n",
    "\n",
    "\n",
    "# def CorrectMatchedDaughters(row):\n",
    "#     matched_showers, matched_tracks            = list(row['matched_showers']),list(row['matched_tracks'])\n",
    "#     nu_shower_ids, nu_track_ids                = row['nu_shower_ids'],row['nu_track_ids']\n",
    "#     nu_shower_daughters, nu_track_daughters    = list(row['nu_shower_daughters']),list(row['nu_track_daughters'])\n",
    "#     # check if there are unmatched shower daughters:\n",
    "#     err = -2147483648\n",
    "#     if err in matched_showers:\n",
    "#         index = matched_showers.index(err)\n",
    "#         pf    = nu_shower_ids[index]\n",
    "#         pdg=0\n",
    "#         print(pf)\n",
    "#         print(nu_shower_daughters)\n",
    "#         if [pf] in nu_shower_daughters:\n",
    "#             pdg = matched_showers[nu_shower_daughters.index([pf])]\n",
    "#         if [pf] in nu_track_daughters:\n",
    "#             pdg = matched_tracks[nu_track_daughters.index([pf])]\n",
    "#         matched_showers[index]=pdg*100\n",
    "#     #now for matched tracks\n",
    "#     if err in matched_tracks:\n",
    "#         index = matched_tracks.index(err)\n",
    "#         pf    = nu_track_ids[index]\n",
    "#         pdg=0\n",
    "#         if [pf] in nu_shower_daughters:\n",
    "#             pdg = matched_showers[nu_shower_daughters.index([pf])]\n",
    "#         if [pf] in nu_track_daughters:\n",
    "#             pdg = matched_tracks[nu_track_daughters.index([pf])]\n",
    "#         matched_tracks[index]=pdg*100  \n",
    "#     return pd.Series({\"matched_showers\": matched_showers, \"matched_tracks\": matched_tracks})\n",
    "\n",
    "def DaughterInfo(row):\n",
    "    nu_shower_ids, nu_track_ids                = row['nu_shower_ids'],row['nu_track_ids']\n",
    "    nu_shower_daughters, nu_track_daughters    = list(row['nu_shower_daughters']),list(row['nu_track_daughters'])\n",
    "\n",
    "    showerdaughter = []\n",
    "    for sh in nu_shower_daughters:\n",
    "        if len(sh)==0:\n",
    "            showerdaughter.append(0)\n",
    "        elif len(sh)==1:\n",
    "            if sh[0] in nu_shower_ids:\n",
    "                showerdaughter.append(1)\n",
    "            elif sh[0] in nu_track_ids:\n",
    "                showerdaughter.append(2)\n",
    "        else:\n",
    "            showerdaughter.append(3)\n",
    "            \n",
    "    trackdaughter = []\n",
    "    for tr in nu_track_daughters:\n",
    "        if len(tr)==0:\n",
    "            trackdaughter.append(0)\n",
    "        elif len(tr)==1:\n",
    "            if tr[0] in nu_shower_ids:\n",
    "                trackdaughter.append(1)\n",
    "            elif tr[0] in nu_track_ids:\n",
    "                trackdaughter.append(2)\n",
    "        else:\n",
    "            trackdaughter.append(3)\n",
    "    return pd.Series({\"shower_daughter\": showerdaughter, \"track_daughter\": trackdaughter})      \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Return true if the point is in the TPC with a tolerance.\n",
    "def CheckBorderTPC(x,y,z,tolerance=0):\n",
    "    detectorx   =256.35     # In cm\n",
    "    detectory   =116.5      # Symmetric around 0     \n",
    "    detectorz   =1036.8\n",
    "    d=tolerance # border tolerance\n",
    "    if (0+d) < x < (detectorx-d):\n",
    "            if (-detectory+d)< y < (detectory-d):\n",
    "                    if (0+d) < z < (detectorz-d):\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "def CheckBorderFid(x,y,z,arr):\n",
    "    detectorx   =256.35     # In cm\n",
    "    detectory   =116.5      # Symmetric around 0     \n",
    "    detectorz   =1036.8\n",
    "    if (0+arr[0][0]) < x < (detectorx-arr[0][1]):\n",
    "            if (-detectory+arr[1][0])< y < (detectory-arr[1][1]):\n",
    "                    if (0+arr[2][0]) < z < (detectorz-arr[2][1]):\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Return the angle between two numpy vectors.\n",
    "def anglevec(v1,v2):\n",
    "    v1_u = v1 / np.linalg.norm(v1)\n",
    "    v2_u = v2 / np.linalg.norm(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "\n",
    "# Verifies if the event passed the flash precuts.\n",
    "def flash_precut(row):\n",
    "    #Flash precuts\n",
    "    t_start = 3.2\n",
    "    t_end   = t_start+1.6\n",
    "    min_PE  = 50\n",
    "\n",
    "    for time,PE in zip(row['flash_time'],row['flash_PE']):\n",
    "        if time>t_start and time<t_end and PE>min_PE:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Sum reconstructed energy\n",
    "def CalcRecoE(row):\n",
    "    reco_energy = [0,0,0,0]\n",
    "    total_nhits = [0,0,0]\n",
    "    \n",
    "    for tr_hits,tr_dedx,nhits in zip(row['track_energy_hits'],row['track_energy_dedx'],row[\"track_nhits\"]):\n",
    "        reco_energy[:3]+=tr_hits  \n",
    "        reco_energy[-1]+=tr_dedx \n",
    "        total_nhits+=nhits\n",
    "        \n",
    "    for shower,nhits in zip(row['shower_energy'],row[\"shower_nhits\"]):\n",
    "        reco_energy[:3]+=shower\n",
    "        reco_energy[-1]+=shower[2] #4th entry uses plane 2 hits for showers and dedx for tracks\n",
    "        total_nhits+=nhits\n",
    "        \n",
    "    return pd.Series({\"reconstructed_energy\": reco_energy, \"total_nhits\": total_nhits})\n",
    "\n",
    "# Signal Definition 1e0p \n",
    "def true_thresholds_1e0p(row):\n",
    "    for pdg,E in zip(row[\"nu_daughters_pdg\"],row[\"nu_daughters_E\"]):\n",
    "        if pdg==11 and E>min_e:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Signal Definition 1e0p \n",
    "def true_thresholds_1eNp(row):\n",
    "    passed_e=False\n",
    "    passed_p=False\n",
    "    for pdg,E in zip(row[\"nu_daughters_pdg\"],row[\"nu_daughters_E\"]):\n",
    "        if pdg==11 and E>min_e:\n",
    "            passed_e=True\n",
    "        if pdg==2212 and E>min_p:\n",
    "            passed_p=True\n",
    "    return passed_e and passed_p\n",
    "\n",
    "# Formatting\n",
    "def sciNot(x):\n",
    "    x=float(x)\n",
    "    return \"{:.1f}\".format(x)\n",
    "\n",
    "# Calculates the true end point for electron showers, for 95% of energy\n",
    "def showerTrueEnd(row):\n",
    "    i_daughter = np.argwhere(row['nu_daughters_pdg']==11)\n",
    "    if len(i_daughter[0])>1:\n",
    "        print('More than 1 true electron daughter')\n",
    "    i_daughter = i_daughter[0][0]\n",
    "    \n",
    "    E_ratio = (row['nu_daughters_E'][i_daughter])/E_c\n",
    "    t_max = np.log(E_ratio)-1.0\n",
    "    length = (t_max+0.08*18+9.6)*X_o\n",
    "    #print('E_ratio',E_ratio,'E',row['nu_daughters_E'][i_daughter],' t_max',t_max,'length',length)\n",
    "    direction = np.array([row['nu_daughters_px'][i_daughter],row['nu_daughters_py'][i_daughter],row['nu_daughters_pz'][i_daughter]])\n",
    "    true_shower_start = np.array([row['nu_daughters_vx'][i_daughter],row['nu_daughters_vy'][i_daughter],row['nu_daughters_vz'][i_daughter]])\n",
    "    true_shower_end = true_shower_start+length*direction/np.linalg.norm(direction)\n",
    "    true_shower_tmax = true_shower_start+(t_max*X_o)*direction/np.linalg.norm(direction)\n",
    "    \n",
    "    return pd.Series({\"true_shower_endx\": true_shower_end[0], \"true_shower_endy\": true_shower_end[1], \"true_shower_endz\": true_shower_end[2],\n",
    "                      \"true_shower_tmax_x\": true_shower_tmax[0], \"true_shower_tmax_y\": true_shower_tmax[1], \"true_shower_tmax_z\": true_shower_tmax[2]})\n",
    "\n",
    "def showerRecoEnd(row):\n",
    "    for x,y,z,px,py,pz,l in zip(row['shower_start_x'],row['shower_start_y'],row['shower_start_z'],row['shower_dir_x'],row['shower_dir_y'],row['shower_dir_z'],row['shower_length']):\n",
    "        start=np.array([x,y,z])\n",
    "        direc=np.array([px,py,pz])\n",
    "        end=start+l*direc/np.linalg.norm(direc)\n",
    "        if not CheckBorderTPC(*end,tolerance=fid_min):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def TrackRecoEnd(row):\n",
    "    for x,y,z in zip(row['track_end_x'],row['track_end_y'],row['track_end_z']):\n",
    "        if not CheckBorderTPC(x,y,z,tolerance=fid_min):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Calculates the percentage of sps inside the fiducial volume and the percentage of deposited collection plane charge\n",
    "def containedPercent(row):\n",
    "    d=0.01\n",
    "    n=0.0\n",
    "    \n",
    "    for x,y,z,q in zip(row['shower_sp_x'],row['shower_sp_y'],row['shower_sp_z'],row['shower_sp_int']):\n",
    "        d+=q\n",
    "        if CheckBorderFid(x,y,z,fid_arr):\n",
    "            n+=q\n",
    "\n",
    "    return n/d\n",
    "\n",
    "def shower_nhits_plane(shower_nhits):\n",
    "    sh_hits_plane =0 \n",
    "    for sh in shower_nhits:\n",
    "        sh_hits_plane+=sh[2] # Collection plane\n",
    "    return sh_hits_plane\n",
    "\n",
    "def CC_daughter_E(row):\n",
    "    CC_daughter_i = numpy.in1d(row['nu_daughters_pdg'], [11,-11,13,-13])\n",
    "    CC_daughter_E = -1\n",
    "    if len(CC_daughters)>0:\n",
    "        if len(CC_daughters)>2:\n",
    "            'Multiple electron/muon daughters found!'\n",
    "        else:      \n",
    "            CC_daughter_E = row['nu_daughters_E'][CC_daughter_i[0]]\n",
    "    return CC_daughter_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_columns(df_shower):\n",
    "    # Calculate the true end point of electron showers\n",
    "    df_shower[['true_shower_endx','true_shower_endy','true_shower_endz','true_shower_tmax_x','true_shower_tmax_y','true_shower_tmax_z']]=df_shower.apply(showerTrueEnd,axis=1)\n",
    "    # Calculate true containment of electron showers\n",
    "    df_shower['e_contained']=df_shower.apply(lambda x: CheckBorderTPC(x['true_shower_endx'],x['true_shower_endy'],x['true_shower_endz']), axis=1)\n",
    "    df_shower['e_contained_tmax']=df_shower.apply(lambda x: CheckBorderTPC(x['true_shower_tmax_x'],x['true_shower_tmax_y'],x['true_shower_tmax_z']), axis=1)\n",
    "    # Calculate reco containment of showers spacepoints\n",
    "    df_shower['shower_containment_q']=df_shower[['shower_sp_x','shower_sp_y','shower_sp_z','shower_sp_int']].apply(containedPercent,axis=1)\n",
    "    # Calculate reco containment of shower lengths\n",
    "    df_shower['reco_length_containment']=df_shower.apply(showerRecoEnd,axis=1) \n",
    "    # Return true in case more energy is deposited in the start or in the end of the shower\n",
    "    df_shower['shower_sp_profile']=df_shower[['vx','vy','vz','shower_sp_x','shower_sp_y','shower_sp_z','shower_sp_int']].apply(showerChargeProfile,axis=1)\n",
    "    # Fix matched daughters WORK IN PROGRESS\n",
    "    df_shower['shower_daughter','track_daughter']=df_shower.apply(DaughterInfo,axis=1)\n",
    "    return df_shower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load root files into a dataframe or dictionary of dataframes.\n",
    "\n",
    "def loadData(filelist,                  # List of input files\n",
    "             columns,                   # List of fields (columns) to include in the dataframe  \n",
    "             maxf=1,                    # Maximum number of files to loop over\n",
    "             contained=True,            # Is the true neutrino interaction in a defined volume?\n",
    "             truecontains=[11,2212],    # Require the true neutrino interaction to have the following daughters.\n",
    "             LEE_denom=False,           # 1 proton of at least 40MeV, 1 electron of at least 20MeV, true vertex inside: x[10,10],y[20,20],z[10,50]\n",
    "             Nue_inclusive=True,        # 1 electron of at least 20MeV, true vertex inside: x[10,10],y[20,20],z[10,50]\n",
    "             flashpassed=True,          # Output only rows with a candidate passing the optical selection\n",
    "             passed=True,               # Output only rows with a candidate passing the selection\n",
    "             returnpure=False ):        # Output only rows with a candidate passing that is within 5cm and nu or mixed category.\n",
    "                     \n",
    "    columns_req = ['true_vx','true_vy','true_vz','bnbweight',\n",
    "                   'nu_daughters_vx','nu_daughters_vy','nu_daughters_vz',\n",
    "                   'flash_time','flash_PE',\n",
    "                   'nu_daughters_pdg','nu_daughters_E','nu_daughters_px','nu_daughters_py','nu_daughters_pz',\n",
    "                   'flash_passed','passed','category','distance',\n",
    "                   'track_energy_hits','shower_energy','track_energy_dedx','shower_nhits','track_nhits',\n",
    "                   'true_shower_x_sce','true_shower_x_sce',\"true_shower_x_sce\",\"true_shower_pdg\",\n",
    "                   'shower_start_x','shower_start_y','shower_start_z',\n",
    "                   'shower_sp_x','shower_sp_y','shower_sp_z','shower_sp_int',\n",
    "                   'shower_length',\"shower_dir_x\",\"shower_dir_y\",\"shower_dir_z\"\n",
    "                  ]\n",
    "    columns_remove = [item for item in columns_req if item not in columns]\n",
    "    \n",
    "    global categories\n",
    "    global fid_arr\n",
    "    chunks=[]\n",
    "    chunks_all=[]\n",
    "    columns_all = list(set(columns) | set(columns_req))\n",
    "    \n",
    "    entries=0\n",
    "    entries_contained=0\n",
    "    entries_truecontains=[0]*len(truecontains)\n",
    "    entries_sig_def=0\n",
    "    entries_valid_flash=0\n",
    "    entries_flashpassed=0\n",
    "    entries_passed=0\n",
    "    entries_reco_fiducial=0\n",
    "    entries_hitcut=0\n",
    "    entries_sh_cont=0\n",
    "    entries_tr_cont=0\n",
    "    entries_tr_score=0\n",
    "    \n",
    "    entries_noncosmic=0\n",
    "    entries_pure=0\n",
    "    entries_pure_plus=0\n",
    "    entries_noncosmic_test=0\n",
    "    entries_pure_test=0\n",
    "    entries_pure_plus_test=0\n",
    "    \n",
    "    entries_final=0\n",
    "    \n",
    "    total_pot=0\n",
    "    \n",
    "    nfiles=len(filelist)\n",
    "    if maxf<nfiles:\n",
    "        nfiles=maxf\n",
    "    \n",
    "    print\n",
    "    #print(columns_remove)\n",
    "    print ('Start to load entries from',nfiles,'files.\\n')\n",
    "    start_time = time.time()\n",
    "    \n",
    "    progress=0\n",
    "    for i_f,fname in enumerate(filelist[:nfiles]):\n",
    "        if(i_f % math.ceil(nfiles/10)==0 ):\n",
    "            print ('Progress:',progress,'%.')\n",
    "            progress+=10\n",
    "        \n",
    "        if (os.stat(fname).st_size)<50000:\n",
    "            print('File',fname,'was corrupt. Size:',os.stat(fname).st_size/1000, 'kb, skipping to next file.')\n",
    "            continue\n",
    "        \n",
    "        dftemp=read_root(fname,\"robertoana/pandoratree\",columns=columns_all)\n",
    "        \n",
    "        #store the POT of the sample\n",
    "        total_pot+=read_root(fname,\"robertoana/pot\",columns='pot').sum()\n",
    "        \n",
    "        entries+=len(dftemp.index)\n",
    "        \n",
    "        if contained:\n",
    "            dftemp=dftemp[dftemp.apply(lambda x: CheckBorderFid(x['true_vx_sce'],x['true_vy_sce'],x['true_vz_sce'],fid_arr), axis=1)]\n",
    "            entries_contained+=len(dftemp.index)\n",
    "            \n",
    "        for i,pdg in enumerate(truecontains):\n",
    "            dftemp = dftemp[dftemp[\"nu_daughters_pdg\"].apply(lambda x: pdg in x)]\n",
    "            entries_truecontains[i]+=len(dftemp.index)\n",
    "        \n",
    "        if Nue_inclusive or LEE_denom:\n",
    "            #dftemp = dftemp[dftemp.apply(lambda x: CheckBorderFid(x['true_vx'],x['true_vy'],x['true_vz'],fid_arr), axis=1)]\n",
    "            if Nue_inclusive:\n",
    "                dftemp = dftemp[dftemp[[\"nu_daughters_pdg\",\"nu_daughters_E\"]].apply(true_thresholds_1e0p, axis=1)]\n",
    "            if LEE_denom:\n",
    "                dftemp = dftemp[dftemp[[\"nu_daughters_pdg\",\"nu_daughters_E\"]].apply(true_thresholds_1eNp, axis=1)]\n",
    "            entries_sig_def+=len(dftemp.index)\n",
    "        \n",
    "        # Up to here you do true cuts on the sample to define the signal, before you do cuts, safe some fields:\n",
    "        df_all_temp = dftemp[['true_shower_x_sce','true_shower_y_sce','true_shower_z_sce',\n",
    "                             'nu_E','bnbweight','nu_daughters_pdg','nu_daughters_E']]\n",
    "        \n",
    "        dftemp = dftemp[dftemp.apply(flash_precut, axis=1)]\n",
    "        entries_valid_flash+=len(dftemp.index)\n",
    "            \n",
    "        if flashpassed:\n",
    "            dftemp = dftemp[ dftemp['flash_passed'].apply(lambda x: not np.all(x==-1))]\n",
    "            entries_flashpassed+=len(dftemp.index)\n",
    "            \n",
    "        if passed:\n",
    "            dftemp=dftemp[dftemp['passed']==1]\n",
    "            entries_passed+= len(dftemp.index)\n",
    "        \n",
    "        # reconstructed vertex in fiducial volume\n",
    "        dftemp=dftemp[dftemp.apply(lambda x: CheckBorderFid(x['vx'],x['vy'],x['vz'],fid_arr), axis=1)]\n",
    "        entries_reco_fiducial+=len(dftemp.index)\n",
    "           \n",
    "        # Do calculations with the small dataframe\n",
    "        dftemp = add_columns(dftemp)\n",
    "        \n",
    "        # 5 hit min cut:\n",
    "        dftemp['plane2']=dftemp['shower_nhits'].apply(shower_nhits_plane)\n",
    "        df_test = dftemp[dftemp['plane2']>5]\n",
    "        entries_hitcut+=len(df_test.index)\n",
    "        \n",
    "        # Shower containment\n",
    "        df_test = df_test[df_test['shower_containment_q']>sh_cont_percent]\n",
    "        #df_test = df_test[df_test['reco_length_containment']]\n",
    "        entries_sh_cont+=len(df_test.index)\n",
    "        \n",
    "        # Track containment\n",
    "        df_test=df_test[df_test.apply(TrackRecoEnd, axis=1)]\n",
    "        entries_tr_cont+=len(df_test.index)\n",
    "        \n",
    "        # Track score \n",
    "        df_test=df_test[df_test.apply(lambda x: np.all(x['predict_p']>0.0003), axis=1)]\n",
    "        entries_tr_score+=len(df_test.index)\n",
    "\n",
    "        \n",
    "        entries_noncosmic+= len(dftemp[dftemp['category'].isin([2,3,7]) ].index)\n",
    "\n",
    "        entries_pure+= len(dftemp[ (dftemp['distance']<5) & \n",
    "                                   (dftemp['category'].isin([2,3,7]))  ].index)\n",
    "           \n",
    "        entries_pure_plus+= len(dftemp[ (dftemp['distance']<5) & \n",
    "                                   (dftemp['category'].isin([2,3]))  ].index)\n",
    "        \n",
    "        entries_noncosmic_test+= len(df_test[df_test['category'].isin([2,3,7]) ].index)\n",
    "\n",
    "        entries_pure_test+= len(df_test[ (df_test['distance']<5) & \n",
    "                                   (df_test['category'].isin([2,3,7]))  ].index)\n",
    "        \n",
    "        entries_pure_plus_test+= len(df_test[ (df_test['distance']<5) & \n",
    "                                   (df_test['category'].isin([2,3]))  ].index)\n",
    "            \n",
    "            \n",
    "        if returnpure:\n",
    "            dftemp = dftemp[ (dftemp['category'].isin([2,3,7])) & (dftemp['distance']<5) ]\n",
    "            \n",
    "        entries_final+=len(dftemp.index)\n",
    "        \n",
    "        dftemp[\"category\"]=dftemp[\"category\"].map(categories)        \n",
    "        dftemp[['reconstructed_energy','total_nhits']]=dftemp[[\"track_energy_hits\",\"shower_energy\",'track_energy_dedx',\"shower_nhits\",\"track_nhits\"]].apply(CalcRecoE,axis=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Remove columns from the small dataframe\n",
    "        dftemp.drop(columns_remove,axis=1,inplace=True)\n",
    "        dftemp.drop(columns_remove_extra,axis=1,inplace=True)\n",
    "        \n",
    "        chunks.append(dftemp)\n",
    "        chunks_all.append(df_all_temp)\n",
    "        \n",
    "    print('\\nSummary:')\n",
    "    print (entries,'entries were loaded from',nfiles,'files, corresponding to',str(total_pot[0]),'POT.')\n",
    "    print (entries_contained, 'entries with true vertex in TPC.')\n",
    "    for nr,pdg in zip(entries_truecontains,truecontains):\n",
    "        print (nr, 'entries with a pdg',pdg,'particle.')\n",
    "    print (entries_sig_def, 'entries with the signal definition.')\n",
    "    print (entries_valid_flash, 'entries with a valid flash.')\n",
    "    print (entries_flashpassed, 'entries passing the optical selection.')\n",
    "    print (entries_passed, 'entries passing the selection.')\n",
    "    print (entries_reco_fiducial, 'entries have reco vertex in fiducial volume.\\n')\n",
    "    print (entries_hitcut,' entries with at least 5 shower hit on plane2')\n",
    "    print (entries_sh_cont,' entries with contained showers')\n",
    "    print (entries_tr_cont,' entries with contained tracks')\n",
    "    print (entries_tr_score,' entries with a minimum track score\\n')\n",
    "    \n",
    "    print ('Category efficiency :', entries_noncosmic,'/', entries_sig_def,'(',sciNot(entries_noncosmic/entries_sig_def*100),'%)','signal events passed and category nu or mixed.')\n",
    "    print ('Closeness purity :', entries_pure,'/', entries_reco_fiducial,'(',sciNot(entries_pure/entries_reco_fiducial*100),'%)','of passed events is within 5cm from true_sce vertex and category nu or mixed.')\n",
    "    print ('Closeness purity plus :', entries_pure_plus,'/', entries_reco_fiducial,'(',sciNot(entries_pure_plus/entries_reco_fiducial*100),'%)','of passed events is within 5cm from true_sce vertex and category nu.')\n",
    "    print (entries_final,'entries in the final dataframe.\\n')\n",
    "    \n",
    "    print ('Category efficiency test:', entries_noncosmic_test,'/', entries_sig_def,'(',sciNot(entries_noncosmic_test/entries_sig_def*100),'%)','signal events passed and category nu or mixed.')\n",
    "    print ('Closeness purity test:', entries_pure_test,'/', entries_tr_score,'(',sciNot(entries_pure_test/entries_tr_score*100),'%)','of passed events is within 5cm from true_sce vertex and category nu or mixed.')\n",
    "    print ('Closeness purity plus test:', entries_pure_plus_test,'/', entries_tr_score,'(',sciNot(entries_pure_plus_test/entries_tr_score*100),'%)','of passed events is within 5cm from true_sce vertex and category nu.')\n",
    "\n",
    "    print('Concatenating selection dataframe')\n",
    "    df = pd.concat(chunks,ignore_index=True,copy=False) \n",
    "    print('Concatenating full slimmed dataframe')\n",
    "    df_all = pd.concat(chunks_all,ignore_index=True,copy=False) \n",
    "    df_all.to_pickle('Input/all_events.pckl')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print('Loading took ',sciNot(end_time-start_time),' seconds.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataframe and save to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to load entries from 308 files.\n",
      "\n",
      "Progress: 0 %.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wouter/anaconda3/envs/rootenv/lib/python3.4/site-packages/ipykernel/__main__.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/wouter/anaconda3/envs/rootenv/lib/python3.4/site-packages/ipykernel/__main__.py:18: RuntimeWarning: invalid value encountered in float_scalars\n",
      "/home/wouter/anaconda3/envs/rootenv/lib/python3.4/site-packages/ipykernel/__main__.py:18: RuntimeWarning: divide by zero encountered in float_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10 %.\n",
      "Progress: 20 %.\n",
      "Progress: 30 %.\n",
      "Progress: 40 %.\n",
      "Progress: 50 %.\n",
      "Progress: 60 %.\n",
      "Progress: 70 %.\n",
      "Progress: 80 %.\n",
      "Progress: 90 %.\n",
      "\n",
      "Summary:\n",
      "555000 entries were loaded from 308 files, corresponding to 6.80934030618e+22 POT.\n",
      "187198 entries with true vertex in TPC.\n",
      "139478 entries with a pdg 11 particle.\n",
      "139394 entries with the signal definition.\n",
      "134667 entries with a valid flash.\n",
      "128127 entries passing the optical selection.\n",
      "112122 entries passing the selection.\n",
      "104716 entries have reco vertex in fiducial volume.\n",
      "\n",
      "102996  entries with at least 5 shower hit on plane2\n",
      "87030  entries with contained showers\n",
      "73992  entries with contained tracks\n",
      "70824  entries with a minimum track score\n",
      "\n",
      "Category efficiency : 102600 / 139394 ( 73.6 %) signal events passed and category nu or mixed.\n",
      "Closeness purity : 77357 / 104716 ( 73.9 %) of passed events is within 5cm from true_sce vertex and category nu or mixed.\n",
      "Closeness purity plus : 65338 / 104716 ( 62.4 %) of passed events is within 5cm from true_sce vertex and category nu.\n",
      "104716 entries in the final dataframe.\n",
      "\n",
      "Category efficiency test: 70346 / 139394 ( 50.5 %) signal events passed and category nu or mixed.\n",
      "Closeness purity test: 54652 / 70824 ( 77.2 %) of passed events is within 5cm from true_sce vertex and category nu or mixed.\n",
      "Closeness purity plus test: 49288 / 70824 ( 69.6 %) of passed events is within 5cm from true_sce vertex and category nu.\n",
      "Concatenating selection dataframe\n",
      "Concatenating full slimmed dataframe\n",
      "Loading took  1427.8  seconds.\n"
     ]
    }
   ],
   "source": [
    "df= loadData(filelist,                  # List of input files\n",
    "             columns,                   # List of fields (columns) to include in the dataframe  \n",
    "             maxf=400,                    # Maximum number of files to loop over\n",
    "             contained=True,            # Is the true neutrino interaction in a defined volume?\n",
    "             truecontains=[11],         # Require the true neutrino interaction to have the following daughters.\n",
    "             LEE_denom=False,           # 1 proton of at least 40MeV, 1 electron of at least 20MeV, true vertex inside: x[10,10],y[20,20],z[10,50]\n",
    "             Nue_inclusive=True,        # 1 electron of at least 20MeV, true vertex inside: x[10,10],y[20,20],z[10,50]\n",
    "             flashpassed=True,          # Output only rows with a candidate passing the optical selection\n",
    "             passed=True,               # Output only rows with a candidate passing the selection\n",
    "             returnpure=False )         # Output only rows with a candidate passing that is within 5cm and not a cosmic.\n",
    "\n",
    "df.to_pickle('Input/nue_cosmic_passed_LEEdef.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.bool_' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-70dad6746950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shower_sp_profile'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#df.info(memory_usage='deep')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#df.memory_usage(deep=True)[:25]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.bool_' has no len()"
     ]
    }
   ],
   "source": [
    "len(df['shower_sp_profile'][0])\n",
    "#df.info(memory_usage='deep') \n",
    "#df.memory_usage(deep=True)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "d=2\n",
    "print(max(df['shower_sp_profile'][d]))\n",
    "plt.hist(df['shower_sp_profile'][d],weights = df['shower_sp_int'][d])\n",
    "y,x = np.histogram( df['shower_sp_profile'][d],weights = df['shower_sp_int'][d] )\n",
    "print(np.mean(y[:5])/np.mean(y[-5:])>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['nu_track_ids','nu_shower_ids','nu_shower_daughters','nu_track_daughters','matched_showers','matched_tracks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rootenv]",
   "language": "python",
   "name": "conda-env-rootenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
